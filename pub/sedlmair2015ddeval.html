<!DOCTYPE html>
    <html lang="en">
    <head>
      <meta charset="UTF-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <title>Data-driven Evaluation of Visual Quality Measures | VISVAR Research Group, University of Stuttgart</title>
      <link rel="stylesheet" href="../style.css">
      <link rel="shortcut icon" href="../img/favicon.png">
      <link rel="icon" type="image/png" href="../img/favicon.png" sizes="256x256">
      <link rel="apple-touch-icon" sizes="256x256" href="../img/favicon.png">
    </head>
    <body>
      <a class="anchor" name="top"></a>
      <main>
        
<div>
  <header>
    <div>
      <a href="https://visvar.github.io/">
        <img class="logo" src="https://visvar.github.io/img/visvar_logo.svg" />
      </a>
    </div>
    <div>
      <nav>
      <ul>
        <li><a href="https://visvar.github.io/#aboutus">about VISVAR</a></li>
        <li><a href="https://visvar.github.io/#publications">publications</a></li>
        <li><a href="https://visvar.github.io/#members">members</a></li>
        <ul class="memberNav">
          
          <li><a href="https://visvar.github.io/members/michael_sedlmair.html">Michael Sedlmair</a></li>
          
          <li><a href="https://visvar.github.io/members/quynh_quang_ngo.html">Quynh Quang Ngo</a></li>
          
          <li><a href="https://visvar.github.io/members/benjamin_lee.html">Benjamin Lee</a></li>
          
          <li><a href="https://visvar.github.io/members/aimee_sousa_calepso.html">Aimee Sousa Calepso</a></li>
          
          <li><a href="https://visvar.github.io/members/alexander_achberger.html">Alexander Achberger</a></li>
          
          <li><a href="https://visvar.github.io/members/frank_heyen.html">Frank Heyen</a></li>
          
          <li><a href="https://visvar.github.io/members/jonas_haischt.html">Jonas Haischt</a></li>
          
          <li><a href="https://visvar.github.io/members/katrin_angerbauer.html">Katrin Angerbauer</a></li>
          
          <li><a href="https://visvar.github.io/members/markus_wieland.html">Markus Wieland</a></li>
          
          <li><a href="https://visvar.github.io/members/melissa_reinelt.html">Melissa Reinelt</a></li>
          
          <li><a href="https://visvar.github.io/members/natalie_hube.html">Natalie Hube</a></li>
          
          <li><a href="https://visvar.github.io/members/nina_doerr.html">Nina Doerr</a></li>
          
          <li><a href="https://visvar.github.io/members/rene_cutura.html">Rene Cutura</a></li>
          
          <li><a href="https://visvar.github.io/members/ruben_bauer.html">Ruben Bauer</a></li>
          
          <li><a href="https://visvar.github.io/members/sebastian_rigling.html">Sebastian Rigling</a></li>
          
          <li><a href="https://visvar.github.io/members/simeon_rau.html">Simeon Rau</a></li>
          
          <li><a href="https://visvar.github.io/members/tobias_rau.html">Tobias Rau</a></li>
          
          <li><a href="https://visvar.github.io/members/xingyao_yu.html">Xingyao Yu</a></li>
          
        </ul>
      </ul>
      </nav>
    </div>
  </header>
</div>

        <div>
          <article><a class="anchor" name="publications"></a>
            <h1>Data-driven Evaluation of Visual Quality Measures</h1>
            <div class="pubPageContent">
              <img id="imagesedlmair2015ddeval" src="../img/sedlmair2015ddeval.png"/>
              <div>
                <b>Venue.</b> CGF (2015) 
              </div>
              <div>
                <b>Authors.</b> Michael Sedlmair, Michael Aupetit
              </div>
              <div>
                <b>Materials.</b>
                <a href="https://doi.org/10.1111/cgf.12632" target="_blank">website</a>
                <a href="../pdf/sedlmair2015ddeval.pdf" target="_blank">PDF</a>
                
                
              </div>
              <div class="abstract"><b>Abstract.</b> Visual quality measures seek to algorithmically imitate human judgments of patterns such as class separability, correlation, or outliers. In this paper, we propose a novel data-driven framework for evaluating such measures. The basic idea is to take a large set of visually encoded data, such as scatterplots, with reliable human “ground truth” judgements, and to use this human-labeled data to learn how well a measure would predict human judgements on previously unseen data. Measures can then be evaluated based on predictive performance—an approach that is crucial for generalizing across datasets but has gained little attention so far. To illustrate our framework, we use it to evaluate 15 state-of-the-art class separation measures, using human ground truth data from 828 class separation judgments on color-coded 2D scatterplots.</div>
              <div class="bibtex"><textarea>@article{https://doi.org/10.1111/cgf.12632,
    title        = {Data-driven Evaluation of Visual Quality Measures},
    author       = {Sedlmair, M. and Aupetit, M.},
    year         = {2015},
    journal      = {Computer Graphics Forum},
    volume       = {34},
    number       = {3},
    pages        = {201--210},
    doi          = {https://doi.org/10.1111/cgf.12632},
    url          = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.12632},
    keywords     = {Categories and Subject Descriptors (according to ACM CCS), H.5.0 Information Interfaces and Presentation: General},
    eprint       = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.12632},
    abstract     = {Abstract Visual quality measures seek to algorithmically imitate human judgments of patterns such as class separability, correlation, or outliers. In this paper, we propose a novel data-driven framework for evaluating such measures. The basic idea is to take a large set of visually encoded data, such as scatterplots, with reliable human ``ground truth'' judgements, and to use this human-labeled data to learn how well a measure would predict human judgements on previously unseen data. Measures can then be evaluated based on predictive performance--an approach that is crucial for generalizing across datasets but has gained little attention so far. To illustrate our framework, we use it to evaluate 15 state-of-the-art class separation measures, using human ground truth data from 828 class separation judgments on color-coded 2D scatterplots.}
}
</textarea></div>
              
              
              <img class="qr" src="../qr/sedlmair2015ddeval.png"/>
            </div>
          </article>
        </div>
      </main>
    </body>
    </html>