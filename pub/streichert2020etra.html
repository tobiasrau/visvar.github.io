<!DOCTYPE html>
    <html lang="en">
    <head>
      <meta charset="UTF-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <title>Comparing Input Modalities for Shape Drawing Tasks | VISVAR Research Group, University of Stuttgart</title>
      <link rel="stylesheet" href="../style.css">
      <script src="../script.js"></script>
      <link rel="shortcut icon" href="../img/favicon.png">
      <link rel="icon" type="image/png" href="../img/favicon.png" sizes="256x256">
      <link rel="apple-touch-icon" sizes="256x256" href="../img/favicon.png">
    </head>
    <body>
      <a class="anchor" name="top"></a>
      <main>
        <div>
          
<header>
  <div>
    <a href="https://visvar.github.io/">
      <h1 class="h1desktop"><div>VISVAR</div><div>Research</div><div>Group</div></h1>
      <h1 class="h1mobile">VISVAR</h1>
    </a>
  </div>
  <div>
    <nav>
      <ul>
        <li>
          <a href="https://visvar.github.io/#aboutus">about VISVAR</a>
        </li>
        <li>
          <a href="https://visvar.github.io/#publications">publications</a>
        </li>
        <li class="memberNav">
          <a href="https://visvar.github.io/#members">members</a>
        </li>
        <ul class="memberNav">
          
            <li><a href="https://visvar.github.io/members/michael_sedlmair.html">Michael Sedlmair</a></li>
          
            <li><a href="https://visvar.github.io/members/quynh_quang_ngo.html">Quynh Quang Ngo</a></li>
          
            <li><a href="https://visvar.github.io/members/aimee_sousa_calepso.html">Aimee Sousa Calepso</a></li>
          
            <li><a href="https://visvar.github.io/members/alexander_achberger.html">Alexander Achberger</a></li>
          
            <li><a href="https://visvar.github.io/members/frank_heyen.html">Frank Heyen</a></li>
          
            <li><a href="https://visvar.github.io/members/jonas_haischt.html">Jonas Haischt</a></li>
          
            <li><a href="https://visvar.github.io/members/katrin_angerbauer.html">Katrin Angerbauer</a></li>
          
            <li><a href="https://visvar.github.io/members/markus_wieland.html">Markus Wieland</a></li>
          
            <li><a href="https://visvar.github.io/members/melissa_reinelt.html">Melissa Reinelt</a></li>
          
            <li><a href="https://visvar.github.io/members/natalie_hube.html">Natalie Hube</a></li>
          
            <li><a href="https://visvar.github.io/members/nina_doerr.html">Nina DÃ¶rr</a></li>
          
            <li><a href="https://visvar.github.io/members/rene_cutura.html">Rene Cutura</a></li>
          
            <li><a href="https://visvar.github.io/members/ruben_bauer.html">Ruben Bauer</a></li>
          
            <li><a href="https://visvar.github.io/members/sebastian_rigling.html">Sebastian Rigling</a></li>
          
            <li><a href="https://visvar.github.io/members/simeon_rau.html">Simeon Rau</a></li>
          
            <li><a href="https://visvar.github.io/members/tobias_rau.html">Tobias Rau</a></li>
          
            <li><a href="https://visvar.github.io/members/xingyao_yu.html">Xingyao Yu</a></li>
          
        </ul>
      </ul>
    </nav>
  </div>
</header>
        </div>
        <div>
          <article> <a class="anchor" name="publications"></a>
            <h1>Comparing Input Modalities for Shape Drawing Tasks</h1>
            <div class="pubPageContent">
              <img id="imagestreichert2020etra" src="../img/streichert2020etra.png"/>
              <div>
                <b>Venue.</b> ETVIS (2020) Workshop / Short Paper
              </div>
              <div>
                <b>Authors.</b> Annalena Streichert, Katrin Angerbauer, Magdalena Schwarzl, Michael Sedlmair
              </div>
              <div>
                <b>Materials.</b>
                <a href="https://doi.org/10.1145/3379156.3391830" target="_blank">website</a>
                <a href="../pdf/streichert2020etra.pdf" target="_blank">PDF</a>
                
                
              </div>
              <div class="abstract"><b>Abstract.</b> With the growing interest in Immersive Analytics, there is also a need for novel and suitable input modalities for such applications. We explore eye tracking, head tracking, hand motion tracking, and data gloves as input methods for a 2D tracing task and compare them to touch input as a baseline in an exploratory user study (N= 20). We compare these methods in terms of user experience, workload, accuracy, and time required for input. The results show that the input method has a significant influence on these measured variables. While touch input surpasses all other input methods in terms of user experience, workload, and accuracy, eye tracking shows promise in respect of the input time. The results form a starting point for future research investigating input methods.</div>
              <div class="bibtex"><textarea>@inproceedings{10.1145/3379156.3391830,
author = {Streichert, Annalena and Angerbauer, Katrin and Schwarzl, Magdalena and Sedlmair, Michael},
title = {Comparing Input Modalities for Shape Drawing Tasks},
year = {2020},
isbn = {9781450371346},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379156.3391830},
doi = {10.1145/3379156.3391830},
abstract = {With the growing interest in Immersive Analytics, there is also a need for novel and suitable input modalities for such applications. We explore eye tracking, head tracking, hand motion tracking, and data gloves as input methods for a 2D tracing task and compare them to touch input as a baseline in an exploratory user study (N=20). We compare these methods in terms of user experience, workload, accuracy, and time required for input. The results show that the input method has a significant influence on these measured variables. While touch input surpasses all other input methods in terms of user experience, workload, and accuracy, eye tracking shows promise in respect of the input time. The results form a starting point for future research investigating input methods.},
booktitle = {ACM Symposium on Eye Tracking Research and Applications},
articleno = {51},
numpages = {5},
keywords = {Immersive analytics, input modalities, interaction},
location = {Stuttgart, Germany},
series = {ETRA '20 Short Papers}
}</textarea></div>
              
              <img class="qr" src="../qr/streichert2020etra.png"/>
            </div>
          </div>
          </article>
        </div>
      </main>
    </body>
    </html>