<!DOCTYPE html>
    <html lang="en">
    <head>
      <meta charset="UTF-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <title>Towards Immersive Collaborative Sensemaking | VISVAR Research Group, University of Stuttgart</title>
      <link rel="stylesheet" href="../style.css">
      <link rel="shortcut icon" href="../img/favicon.png">
      <link rel="icon" type="image/png" href="../img/favicon.png" sizes="256x256">
      <link rel="apple-touch-icon" sizes="256x256" href="../img/favicon.png">
    </head>
    <body>
      <a class="anchor" name="top"></a>
      <main>
        
<div>
  <header>
    <div>
      <a href="https://visvar.github.io/">
        <img class="logo" src="https://visvar.github.io/img/visvar_logo.svg" />
      </a>
    </div>
    <div>
      <nav>
      <ul>
        <li><a href="https://visvar.github.io/#aboutus">about VISVAR</a></li>
        <li><a href="https://visvar.github.io/#publications">publications</a></li>
        <li><a href="https://visvar.github.io/#members">members</a></li>
        <ul class="memberNav">
          
          <li><a href="https://visvar.github.io/members/michael_sedlmair.html">Michael Sedlmair</a></li>
          
          <li><a href="https://visvar.github.io/members/quynh_quang_ngo.html">Quynh Quang Ngo</a></li>
          
          <li><a href="https://visvar.github.io/members/benjamin_lee.html">Benjamin Lee</a></li>
          
          <li><a href="https://visvar.github.io/members/aimee_sousa_calepso.html">Aimee Sousa Calepso</a></li>
          
          <li><a href="https://visvar.github.io/members/alexander_achberger.html">Alexander Achberger</a></li>
          
          <li><a href="https://visvar.github.io/members/frank_heyen.html">Frank Heyen</a></li>
          
          <li><a href="https://visvar.github.io/members/jonas_haischt.html">Jonas Haischt</a></li>
          
          <li><a href="https://visvar.github.io/members/katrin_angerbauer.html">Katrin Angerbauer</a></li>
          
          <li><a href="https://visvar.github.io/members/markus_wieland.html">Markus Wieland</a></li>
          
          <li><a href="https://visvar.github.io/members/melissa_reinelt.html">Melissa Reinelt</a></li>
          
          <li><a href="https://visvar.github.io/members/natalie_hube.html">Natalie Hube</a></li>
          
          <li><a href="https://visvar.github.io/members/nina_doerr.html">Nina Doerr</a></li>
          
          <li><a href="https://visvar.github.io/members/rene_cutura.html">Rene Cutura</a></li>
          
          <li><a href="https://visvar.github.io/members/ruben_bauer.html">Ruben Bauer</a></li>
          
          <li><a href="https://visvar.github.io/members/sebastian_rigling.html">Sebastian Rigling</a></li>
          
          <li><a href="https://visvar.github.io/members/simeon_rau.html">Simeon Rau</a></li>
          
          <li><a href="https://visvar.github.io/members/tobias_rau.html">Tobias Rau</a></li>
          
          <li><a href="https://visvar.github.io/members/xingyao_yu.html">Xingyao Yu</a></li>
          
        </ul>
      </ul>
      </nav>
    </div>
  </header>
</div>

        <div>
          <article><a class="anchor" name="publications"></a>
            <h1>Towards Immersive Collaborative Sensemaking</h1>
            <div class="pubPageContent">
              <img id="imageyang2022collaborative" src="../img/yang2022collaborative.png"/>
              <div>
                <b>Venue.</b> ACM ISS (2022) 
              </div>
              <div>
                <b>Authors.</b> Ying Yang, Tim Dwyer, Michael Wybrow, Benjamin Lee, Maxime Cordeil, Mark Billinghurst, Bruce H Thomas
              </div>
              <div>
                <b>Materials.</b>
                <a href="https://doi.org/10.1145/3567741" target="_blank">website</a>
                <a href="../pdf/yang2022collaborative.pdf" target="_blank">PDF</a>
                <a href="https://www.youtube.com/watch?v=8AxNxvPAdYk" target="_blank">video</a>
                <a href="https://dl.acm.org/doi/abs/10.1145/3567741#sec-supp" target="_blank">supplemental</a>
              </div>
              <div class="abstract"><b>Abstract.</b> When collaborating face-to-face, people commonly use the surfaces and spaces around them to perform sensemaking tasks, such as spatially organising documents, notes or images. However, when people collaborate remotely using desktop interfaces they no longer feel like they are sharing the same space. This limitation may be overcome through collaboration in immersive environments, which simulate the physical in-person experience. In this paper, we report on a between-groups study comparing collaborations on image organisation tasks, in an immersive Virtual Reality (VR) environment to more conventional desktop conferencing. Collecting data from 40 subjects in groups of four, we measured task performance, user behaviours, collaboration engagement and awareness. Overall, the VR and desktop interface resulted in similar speed, accuracy and social presence rating, but we observed more conversations and interaction with objects, and more equal contributions to the interaction from participants within groups in VR. We also identified differences in coordination and collaborative awareness behaviours between VR and desktop platforms. We report on a set of systematic measures for assessing VR collaborative experience and a new analysis tool that we have developed to capture user behaviours in collaborative setting. Finally, we provide design considerations and directions for future work.</div>
              <div class="bibtex"><textarea>@article{10.1145/3567741,
    title        = {Towards Immersive Collaborative Sensemaking},
    author       = {Yang, Ying and Dwyer, Tim and Wybrow, Michael and Lee, Benjamin and Cordeil, Maxime and Billinghurst, Mark and Thomas, Bruce H.},
    year         = {2022},
    month        = {nov},
    journal      = {Proc. ACM Hum.-Comput. Interact.},
    publisher    = {Association for Computing Machinery},
    volume       = {6},
    number       = {ISS},
    doi          = {10.1145/3567741},
    url          = {https://doi.org/10.1145/3567741},
    issue_date   = {December 2022},
    abstract     = {When collaborating face-to-face, people commonly use the surfaces and spaces around them to perform sensemaking tasks, such as spatially organising documents, notes or images. However, when people collaborate remotely using desktop interfaces they no longer feel like they are sharing the same space. This limitation may be overcome through collaboration in immersive environments, which simulate the physical in-person experience. In this paper, we report on a between-groups study comparing collaborations on image organisation tasks, in an immersive Virtual Reality (VR) environment to more conventional desktop conferencing. Collecting data from 40 subjects in groups of four, we measured task performance, user behaviours, collaboration engagement and awareness. Overall, the VR and desktop interface resulted in similar speed, accuracy and social presence rating, but we observed more conversations and interaction with objects, and more equal contributions to the interaction from participants within groups in VR. We also identified differences in coordination and collaborative awareness behaviours between VR and desktop platforms. We report on a set of systematic measures for assessing VR collaborative experience and a new analysis tool that we have developed to capture user behaviours in collaborative setting. Finally, we provide design considerations and directions for future work.},
    articleno    = {588},
    numpages     = {25},
    keywords     = {Virtual Reality, Collaborative Sensemaking}
}
</textarea></div>
              
              
              <img class="qr" src="../qr/yang2022collaborative.png"/>
            </div>
          </article>
        </div>
      </main>
    </body>
    </html>