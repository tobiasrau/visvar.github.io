<!DOCTYPE html>
    <html lang="en">
    <head>
      <meta charset="UTF-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <title>VR, Gaze, and Visual Impairment: An Exploratory Study of the Perception of Eye Contact across different Sensory Modalities for People with Visual Impairments in Virtual Reality | VISVAR Research Group, University of Stuttgart</title>
      <link rel="stylesheet" href="../style.css">
      <link rel="shortcut icon" href="../img/misc/favicon.png">
      <link rel="icon" type="image/png" href="../img/favicon.png" sizes="256x256">
      <link rel="apple-touch-icon" sizes="256x256" href="../img/favicon.png">
    </head>
    <body>
      <a class="anchor" name="top"></a>
      <main>
        
<div>
  <header>
    <div>
      <a href="https://visvar.github.io/">
        <img class="logo" src="https://visvar.github.io/img/misc/visvar_logo.svg" />
      </a>
    </div>
    <div>
      <nav>
      <ul>
        <li><a href="https://visvar.github.io/#aboutus">about VISVAR</a></li>
        <li><a href="https://visvar.github.io/#publications">publications</a></li>
        <li><a href="https://visvar.github.io/#members">members</a></li>
        <ul class="memberNav">
          
          <li><a href="https://visvar.github.io/members/michael_sedlmair.html">Michael Sedlmair</a></li>
          
          <li><a href="https://visvar.github.io/members/quynh_quang_ngo.html">Quynh Quang Ngo</a></li>
          
          <li><a href="https://visvar.github.io/members/benjamin_lee.html">Benjamin Lee</a></li>
          
          <li><a href="https://visvar.github.io/members/aimee_sousa_calepso.html">Aimee Sousa Calepso</a></li>
          
          <li><a href="https://visvar.github.io/members/alexander_achberger.html">Alexander Achberger</a></li>
          
          <li><a href="https://visvar.github.io/members/frank_heyen.html">Frank Heyen</a></li>
          
          <li><a href="https://visvar.github.io/members/jonas_haischt.html">Jonas Haischt</a></li>
          
          <li><a href="https://visvar.github.io/members/katrin_angerbauer.html">Katrin Angerbauer</a></li>
          
          <li><a href="https://visvar.github.io/members/markus_wieland.html">Markus Wieland</a></li>
          
          <li><a href="https://visvar.github.io/members/melissa_reinelt.html">Melissa Reinelt</a></li>
          
          <li><a href="https://visvar.github.io/members/natalie_hube.html">Natalie Hube</a></li>
          
          <li><a href="https://visvar.github.io/members/nina_doerr.html">Nina Doerr</a></li>
          
          <li><a href="https://visvar.github.io/members/rene_cutura.html">Rene Cutura</a></li>
          
          <li><a href="https://visvar.github.io/members/ruben_bauer.html">Ruben Bauer</a></li>
          
          <li><a href="https://visvar.github.io/members/sebastian_rigling.html">Sebastian Rigling</a></li>
          
          <li><a href="https://visvar.github.io/members/simeon_rau.html">Simeon Rau</a></li>
          
          <li><a href="https://visvar.github.io/members/tobias_rau.html">Tobias Rau</a></li>
          
          <li><a href="https://visvar.github.io/members/xingyao_yu.html">Xingyao Yu</a></li>
          
        </ul>
      </ul>
      </nav>
    </div>
  </header>
</div>

        <div>
          <article><a class="anchor" name="publications"></a>
            <h1>VR, Gaze, and Visual Impairment: An Exploratory Study of the Perception of Eye Contact across different Sensory Modalities for People with Visual Impairments in Virtual Reality</h1>
            <div class="pubPageContent">
              <img id="imagewieland2023vr" src="../img/wieland2023vr.png"/>
              <div>
                <b>Venue.</b> CHI (2023) Extended Abstract
              </div>
              <div>
                <b>Authors.</b> Markus Wieland, Michael Sedlmair, Tonja-Katrin Machulla


              </div>
              <div>
                <b>Materials.</b>
                <a href="https://doi.org/10.1145/3544549.3585726" target="_blank">website</a>
                <a href="../pdf/wieland2023vr.pdf" target="_blank">PDF</a>
                <a href="https://www.youtube.com/watch?v=D9Z9058RyxQ" target="_blank">video</a>
                
              </div>
              <div class="abstract"><b>Abstract.</b> As social virtual reality (VR) becomes more popular, avatars are being designed with realistic behaviors incorporating non-verbal cues like eye contact. However, perceiving eye contact during a onversation can be challenging for people with visual impairments. VR presents an opportunity to display eye contact cues in alternative ways, making them perceivable for people with visual impairments. We performed an exploratory study to gain initial insights on designing eye contact cues for people with visual impairments, including a focus group for a deeper understanding of the topic. We implemented eye contact cues via visual, auditory, and tactile sensory modalities in VR and tested these approaches with eleven participants with visual impairments and collected qualitative feedback. The results show that visual cues indicating the gaze direction were preferred, but auditory and tactile cues were also prevalent as they do not superimpose additional visual information. </div>
              <div class="bibtex"><textarea>@inproceedings{10.1145/3544549.3585726,
    title        = {VR, Gaze, and Visual Impairment: An Exploratory Study of the Perception of Eye Contact across Different Sensory Modalities for People with Visual Impairments in Virtual Reality},
    author       = {Wieland, Markus and Sedlmair, Michael and Machulla, Tonja-Katrin},
    year         = {2023},
    booktitle    = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
    publisher    = {Association for Computing Machinery},
    series       = {CHI EA '23},
    doi          = {10.1145/3544549.3585726},
    url          = {https://doi.org/10.1145/3544549.3585726},
    abstract     = {As social virtual reality (VR) becomes more popular, avatars are being designed with realistic behaviors incorporating non-verbal cues like eye contact. However, perceiving eye contact during a conversation can be challenging for people with visual impairments. VR presents an opportunity to display eye contact cues in alternative ways, making them perceivable for people with visual impairments. We performed an exploratory study to gain initial insights on designing eye contact cues for people with visual impairments, including a focus group for a deeper understanding of the topic. We implemented eye contact cues via visual, auditory, and tactile sensory modalities in VR and tested these approaches with eleven participants with visual impairments and collected qualitative feedback. The results show that visual cues indicating the gaze direction were preferred, but auditory and tactile cues were also prevalent as they do not superimpose additional visual information.},
    articleno    = {313},
    numpages     = {6},
    keywords     = {eye contact, assistive technology, visual impairment, social virtual reality}
}
</textarea></div>
              
              
              <img class="qr" src="../qr/wieland2023vr.png"/>
            </div>
          </article>
        </div>
      </main>
    </body>
    </html>