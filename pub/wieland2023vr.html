<!DOCTYPE html>
  <html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=100%, initial-scale=1">
    <title>VR, Gaze, and Visual Impairment: An Exploratory Study of the Perception of Eye Contact across different Sensory Modalities for People with Visual Impairments in Virtual Reality | HCI Stuttgart</title>
    <link rel="stylesheet" href="../style.css">
    <link rel="shortcut icon" href="../assets/img/misc/favicon.png">
    <link rel="icon" type="image/png" href="../assets/img/misc/favicon.png" sizes="256x256">
    <link rel="apple-touch-icon" sizes="256x256" href="../assets/img/misc/favicon.png">
  </head>
  
    <body>
      <a class="anchor" name="top"></a>
      <main>
        
<div>
  <header>
    <div>
      <a href="../index.html">
        <img class="logo" src="../assets/img/misc/hci.svg" />
      </a>
    </div>
    <div>
      <nav>
      <ul>
        <li><a href="../index.html#aboutus">about us</a></li>
        <li><a href="../index.html#members">members</a></li>
        <li><a href="../index.html#publications">publications</a></li>
      </ul>
      </nav>
    </div>
  </header>
</div>

        <div>
          <article><a class="anchor" name="publications"></a>
            <h1>VR, Gaze, and Visual Impairment: An Exploratory Study of the Perception of Eye Contact across different Sensory Modalities for People with Visual Impairments in Virtual Reality</h1>
            <div class="pubPageContent">
              
              <a href="../assets/img/teaser/wieland2023vr.png" target="_blank" title="show image full size">
                <img id="imagewieland2023vr" src="../assets/img/teaser/wieland2023vr.png"/>
              </a>
              <div>
                <div>
                  <b>Authors.</b> Markus Wieland, Michael Sedlmair, Tonja-Katrin Machulla


                </div>
                <div>
                  <b>Venue.</b> <a href="../venue/chi.html" target="_blank" title="Conference on Human Factors in Computing Systems">CHI</a> (2023) Extended Abstract
                </div>
                
                <div>
                  <b>Type.</b> Extended Abstract
                </div>
                
                <div>
                  <b>Materials.</b>
                  <a href="https://doi.org/10.1145/3544549.3585726" target="_blank" rel="noreferrer">DOI</a>
                  <a href="https://dl.acm.org/doi/abs/10.1145/3544549.3585726" target="_blank" rel="noreferrer">ACM</a>
                  <a href="../assets/pdf/wieland2023vr.pdf" target="_blank" rel="noreferrer">PDF</a>
                  <a href="https://www.youtube.com/watch?v=D9Z9058RyxQ" target="_blank" rel="noreferrer">video</a>
                  
                </div>
                <div class="abstract"><b>Abstract.</b> As social virtual reality (VR) becomes more popular, avatars are being designed with realistic behaviors incorporating non-verbal cues like eye contact. However, perceiving eye contact during a onversation can be challenging for people with visual impairments. VR presents an opportunity to display eye contact cues in alternative ways, making them perceivable for people with visual impairments. We performed an exploratory study to gain initial insights on designing eye contact cues for people with visual impairments, including a focus group for a deeper understanding of the topic. We implemented eye contact cues via visual, auditory, and tactile sensory modalities in VR and tested these approaches with eleven participants with visual impairments and collected qualitative feedback. The results show that visual cues indicating the gaze direction were preferred, but auditory and tactile cues were also prevalent as they do not superimpose additional visual information. </div>
                <div class="bibtex"><textarea>@inproceedings{10.1145/3544549.3585726,
    title        = {VR, Gaze, and Visual Impairment: An Exploratory Study of the Perception of Eye Contact across Different Sensory Modalities for People with Visual Impairments in Virtual Reality},
    author       = {Wieland, Markus and Sedlmair, Michael and Machulla, Tonja-Katrin},
    year         = {2023},
    booktitle    = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
    publisher    = {Association for Computing Machinery},
    series       = {CHI EA '23},
    doi          = {10.1145/3544549.3585726},
    url          = {https://doi.org/10.1145/3544549.3585726},
    abstract     = {As social virtual reality (VR) becomes more popular, avatars are being designed with realistic behaviors incorporating non-verbal cues like eye contact. However, perceiving eye contact during a conversation can be challenging for people with visual impairments. VR presents an opportunity to display eye contact cues in alternative ways, making them perceivable for people with visual impairments. We performed an exploratory study to gain initial insights on designing eye contact cues for people with visual impairments, including a focus group for a deeper understanding of the topic. We implemented eye contact cues via visual, auditory, and tactile sensory modalities in VR and tested these approaches with eleven participants with visual impairments and collected qualitative feedback. The results show that visual cues indicating the gaze direction were preferred, but auditory and tactile cues were also prevalent as they do not superimpose additional visual information.},
    articleno    = {313},
    numpages     = {6},
    keywords     = {eye contact, assistive technology, visual impairment, social virtual reality}
}
</textarea></div>
                
                
                <img class="qr" src="../assets/img/qr/wieland2023vr.png"/>
            </div>
          </article>
          
<div style="text-align: center">
  <a href="../imprint.html">Imprint / Legal Notice</a>
</div>

        </div>
      </main>
    </body>
    </html>