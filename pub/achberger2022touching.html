<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=500, initial-scale=1">
  <title>Touching Data with PropellerHand | VISVAR Research Group, University of Stuttgart</title>
  <link rel="stylesheet" href="../style.css">
  <link rel="shortcut icon" href="../img/misc/favicon.png">
  <link rel="icon" type="image/png" href="../img/favicon.png" sizes="256x256">
  <link rel="apple-touch-icon" sizes="256x256" href="../img/favicon.png">
</head>

    <body>
      <a class="anchor" name="top"></a>
      <main>
        
<div>
  <header>
    <div>
      <a href="https://visvar.github.io/">
        <img class="logo" src="https://visvar.github.io/img/misc/visvar_logo.svg" />
      </a>
    </div>
    <div>
      <nav>
      <ul>
        <li><a href="https://visvar.github.io/#aboutus">about VISVAR</a></li>
        <li><a href="https://visvar.github.io/#publications">publications</a></li>
        <li><a href="https://visvar.github.io/#members">members</a></li>
        <ul class="memberNav">
          
          <li><a href="https://visvar.github.io/members/michael_sedlmair.html">Michael Sedlmair</a></li>
          
          <li><a href="https://visvar.github.io/members/quynh_quang_ngo.html">Quynh Quang Ngo</a></li>
          
          <li><a href="https://visvar.github.io/members/benjamin_lee.html">Benjamin Lee</a></li>
          
          <li><a href="https://visvar.github.io/members/aimee_sousa_calepso.html">Aimee Sousa Calepso</a></li>
          
          <li><a href="https://visvar.github.io/members/alexander_achberger.html">Alexander Achberger</a></li>
          
          <li><a href="https://visvar.github.io/members/frank_heyen.html">Frank Heyen</a></li>
          
          <li><a href="https://visvar.github.io/members/jonas_haischt.html">Jonas Haischt</a></li>
          
          <li><a href="https://visvar.github.io/members/katrin_angerbauer.html">Katrin Angerbauer</a></li>
          
          <li><a href="https://visvar.github.io/members/markus_wieland.html">Markus Wieland</a></li>
          
          <li><a href="https://visvar.github.io/members/melissa_reinelt.html">Melissa Reinelt</a></li>
          
          <li><a href="https://visvar.github.io/members/natalie_hube.html">Natalie Hube</a></li>
          
          <li><a href="https://visvar.github.io/members/nina_doerr.html">Nina Doerr</a></li>
          
          <li><a href="https://visvar.github.io/members/rene_cutura.html">Rene Cutura</a></li>
          
          <li><a href="https://visvar.github.io/members/ruben_bauer.html">Ruben Bauer</a></li>
          
          <li><a href="https://visvar.github.io/members/sebastian_rigling.html">Sebastian Rigling</a></li>
          
          <li><a href="https://visvar.github.io/members/simeon_rau.html">Simeon Rau</a></li>
          
          <li><a href="https://visvar.github.io/members/tobias_rau.html">Tobias Rau</a></li>
          
          <li><a href="https://visvar.github.io/members/xingyao_yu.html">Xingyao Yu</a></li>
          
        </ul>
      </ul>
      </nav>
    </div>
  </header>
</div>

        <div>
          <article><a class="anchor" name="publications"></a>
            <h1>Touching Data with PropellerHand</h1>
            <div class="pubPageContent">
              <img id="imageachberger2022touching" src="../img/achberger2022touching.png"/>
              <div>
                <b>Venue.</b> Journal of Visualization (2022) Full Paper
              </div>
              <div>
                <b>Authors.</b> Alexander Achberger, Frank Heyen, Kresimir Vidackovic, Michael Sedlmair 
              </div>
              <div>
                <b>Materials.</b>
                <a href="https://doi.org/10.1007/s12650-022-00859-2" target="_blank">website</a>
                <a href="../pdf/achberger2022touching.pdf" target="_blank">PDF</a>
                
                
              </div>
              <div class="abstract"><b>Abstract.</b> Immersive analytics often takes place in virtual environments which promise the users immersion. To fulfill this promise, sensory feedback, such as haptics, is an important component, which is however not well supported yet. Existing haptic devices are often expensive, stationary, or occupy the user’s hand, preventing them from grasping objects or using a controller. We propose PropellerHand, an ungrounded hand-mounted haptic device with two rotatable propellers, that allows exerting forces on the hand without obstructing hand use. PropellerHand is able to simulate feedback such as weight and torque by generating thrust up to 11 N in 2-DOF and a torque of 1.87 Nm in 2-DOF. Its design builds on our experience from quantitative and qualitative experiments with different form factors and parts. We evaluated our prototype through a qualitative user study in various VR scenarios that required participants to manipulate virtual objects in different ways, while changing between torques and directional forces. Results show that PropellerHand improves users’ immersion in virtual reality. Additionally, we conducted a second user study in the field of immersive visualization to investigate the potential benefits of PropellerHand there.</div>
              <div class="bibtex"><textarea>@article{achberger2022touching,
    title        = {Touching data with PropellerHand},
    author       = {Achberger, Alexander and Heyen, Frank and Vidackovic, Kresimir and Sedlmair, Michael},
    year         = {2022},
    journal      = {Journal of Visualization},
    doi          = {10.1007/s12650-022-00859-2},
    url          = {https://doi.org/10.1007/s12650-022-00859-2}
}
</textarea></div>
              <div class="abstract"><b>Acknowledgements.</b> Partially supported by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under Germanys Excellence Strategy – EXC 2120/1 – 390831618</div>
              
              <img class="qr" src="../qr/achberger2022touching.png"/>
            </div>
          </article>
        </div>
      </main>
    </body>
    </html>