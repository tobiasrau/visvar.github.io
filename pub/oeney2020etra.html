<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=500, initial-scale=1">
  <title>Evaluation of Gaze Depth Estimation from Eye Tracking in Augmented Reality | VISVAR Research Group, University of Stuttgart</title>
  <link rel="stylesheet" href="../style.css">
  <link rel="shortcut icon" href="../img/misc/favicon.png">
  <link rel="icon" type="image/png" href="../img/favicon.png" sizes="256x256">
  <link rel="apple-touch-icon" sizes="256x256" href="../img/favicon.png">
</head>

    <body>
      <a class="anchor" name="top"></a>
      <main>
        
<div>
  <header>
    <div>
      <a href="https://visvar.github.io/">
        <img class="logo" src="https://visvar.github.io/img/misc/visvar_logo.svg" />
      </a>
    </div>
    <div>
      <nav>
      <ul>
        <li><a href="https://visvar.github.io/#aboutus">about VISVAR</a></li>
        <li><a href="https://visvar.github.io/#publications">publications</a></li>
        <li><a href="https://visvar.github.io/#members">members</a></li>
      </ul>
      </nav>
    </div>
  </header>
</div>

        <div>
          <article><a class="anchor" name="publications"></a>
            <h1>Evaluation of Gaze Depth Estimation from Eye Tracking in Augmented Reality</h1>
            <div class="pubPageContent">
              <img id="imageoeney2020etra" src="../img/oeney2020etra.png"/>
              <div>
                <b>Venue.</b> ETRA (2020) 
              </div>
              <div>
                <b>Authors.</b> Seyda Ã–ney, Nils Rodrigues, Michael Becher, Guido Reina, Thomas Ertl, Michael Sedlmair, Daniel Weiskopf
              </div>
              <div>
                <b>Materials.</b>
                <a href="https://doi.org/10.1145/3379156.3391835" target="_blank">website</a>
                <a href="../pdf/oeney2020etra.pdf" target="_blank">PDF</a>
                
                
              </div>
              <div class="abstract"><b>Abstract.</b> Gaze tracking in 3D has the potential to improve interaction with objects and visualizations in augmented reality. However, previous research showed that subjective perception of distance varies between real and virtual surroundings. We wanted to determine whether objectively measured 3D gaze depth through eye tracking also exhibits differences between entirely real and augmented environments. To this end, we conducted an experiment (N = 25) in which we used Microsoft HoloLens with a binocular eye tracking add-on from Pupil Labs. Participants performed a task that required them to look at stationary real and virtual objects while wearing a HoloLens device. We were not able to find significant differences in the gaze depth measured by eye tracking. Finally, we discuss our findings and their implications for gaze interaction in immersive analytics, and the quality of the collected gaze data. </div>
              <div class="bibtex"><textarea>@inproceedings{10.1145/3379156.3391835,
    title        = {Evaluation of Gaze Depth Estimation from Eye Tracking in Augmented Reality},
    author       = {Oney, Seyda and Rodrigues, Nils and Becher, Michael and Ertl, Thomas and Reina, Guido and Sedlmair, Michael and Weiskopf, Daniel},
    year         = {2020},
    booktitle    = {ACM Symposium on Eye Tracking Research and Applications},
    publisher    = {Association for Computing Machinery},
    series       = {ETRA '20 Short Papers},
    doi          = {10.1145/3379156.3391835},
    url          = {https://doi.org/10.1145/3379156.3391835},
    abstract     = {Gaze tracking in 3D has the potential to improve interaction with objects and visualizations in augmented reality. However, previous research showed that subjective perception of distance varies between real and virtual surroundings. We wanted to determine whether objectively measured 3D gaze depth through eye tracking also exhibits differences between entirely real and augmented environments. To this end, we conducted an experiment (N = 25) in which we used Microsoft HoloLens with a binocular eye tracking add-on from Pupil Labs. Participants performed a task that required them to look at stationary real and virtual objects while wearing a HoloLens device. We were not able to find significant differences in the gaze depth measured by eye tracking. Finally, we discuss our findings and their implications for gaze interaction in immersive analytics, and the quality of the collected gaze data.},
    articleno    = {49},
    numpages     = {5},
    keywords     = {eye tracking, visualization, Augmented reality, depth perception, immersive analytics, user study}
}
</textarea></div>
              
              
              <img class="qr" src="../qr/oeney2020etra.png"/>
            </div>
          </article>
        </div>
      </main>
    </body>
    </html>