<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=500, initial-scale=1">
  <title>Comparing Methods for Mapping Facial Expressions to Enhance Immersive Collaboration with Signs of Emotion | VISVAR Research Group, University of Stuttgart</title>
  <link rel="stylesheet" href="../style.css">
  <link rel="shortcut icon" href="../img/misc/favicon.png">
  <link rel="icon" type="image/png" href="../img/favicon.png" sizes="256x256">
  <link rel="apple-touch-icon" sizes="256x256" href="../img/favicon.png">
</head>

    <body>
      <a class="anchor" name="top"></a>
      <main>
        
<div>
  <header>
    <div>
      <a href="https://visvar.github.io/">
        <img class="logo" src="https://visvar.github.io/img/misc/visvar_logo.svg" />
      </a>
    </div>
    <div>
      <nav>
      <ul>
        <li><a href="https://visvar.github.io/#aboutus">about VISVAR</a></li>
        <li><a href="https://visvar.github.io/#publications">publications</a></li>
        <li><a href="https://visvar.github.io/#members">members</a></li>
      </ul>
      </nav>
    </div>
  </header>
</div>

        <div>
          <article><a class="anchor" name="publications"></a>
            <h1>Comparing Methods for Mapping Facial Expressions to Enhance Immersive Collaboration with Signs of Emotion</h1>
            <div class="pubPageContent">
              <img id="imagehube2020comparing" src="../img/hube2020comparing.png"/>
              <div>
                <b>Venue.</b> ISMAR (2020) Poster / Short Paper
              </div>
              <div>
                <b>Authors.</b> Natalie Hube, Oliver Lenz, Lars Engeln, Rainer Groh, Michael Sedlmair
              </div>
              <div>
                <b>Materials.</b>
                <a href="https://doi.org/10.1109/ISMAR-Adjunct51615.2020.00023" target="_blank">website</a>
                <a href="../pdf/hube2020comparing.pdf" target="_blank">PDF</a>
                
                
              </div>
              <div class="abstract"><b>Abstract.</b> We present a user study comparing a pre-evaluated mapping approach with a state-of-the-art direct mapping method of facial expressions for emotion judgment in an immersive setting. At its heart, the pre-evaluated approach leverages semiotics, a theory used in linguistic. In doing so, we want to compare pre-evaluation with an approach that seeks to directly map real facial expressions onto their virtual counterparts. To evaluate both approaches, we conduct a controlled lab study with 22 participants. The results show that users are significantly more accurate in judging virtual facial expressions with pre-evaluated mapping. Additionally, participants were slightly more confident when deciding on a presented emotion. We could not find any differences regarding potential Uncanny Valley effects. However, the pre-evaluated mapping shows potential to be more convenient in a conversational scenario.</div>
              <div class="bibtex"><textarea>@inproceedings{9288476,
    title        = {Comparing Methods for Mapping Facial Expressions to Enhance Immersive Collaboration with Signs of Emotion},
    author       = {Hube, Natalie and Lenz, Oliver and Engeln, Lars and Groh, Rainer and Sedlmair, Michael},
    year         = {2020},
    booktitle    = {2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)},
    pages        = {30--35},
    doi          = {10.1109/ISMAR-Adjunct51615.2020.00023}
}
</textarea></div>
              
              
              <img class="qr" src="../qr/hube2020comparing.png"/>
            </div>
          </article>
        </div>
      </main>
    </body>
    </html>