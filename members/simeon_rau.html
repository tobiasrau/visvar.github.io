<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Simeon Rau, M.Sc. | VISVAR Research Group, University of Stuttgart</title>
  <link rel="stylesheet" href="../style.css">
  <script src="../script.js"></script>
  <link rel="shortcut icon" href="../img/favicon.png">
  <link rel="icon" type="image/png" href="../img/favicon.png" sizes="256x256">
  <link rel="apple-touch-icon" sizes="256x256" href="../img/favicon.png">
</head>
<body>
  <a class="anchor" name="top"></a>
  <main>
    
<div>
<header>
<div>
<a href="https://visvar.github.io/">
<h1 class="h1desktop"><div>VISVAR</div><div>Research</div><div>Group</div></h1>
<h1 class="h1mobile">VISVAR</h1>
</a>
</div>
<div>
<nav>
<ul>
<li><a href="https://visvar.github.io/#aboutus">about VISVAR</a></li>
<li><a href="https://visvar.github.io/#publications">publications</a></li>
<li class="memberNav"><a href="https://visvar.github.io/#members">members</a></li>
<ul class="memberNav">

<li><a href="https://visvar.github.io/members/michael_sedlmair.html">Michael Sedlmair</a></li>

<li><a href="https://visvar.github.io/members/quynh_quang_ngo.html">Quynh Quang Ngo</a></li>

<li><a href="https://visvar.github.io/members/aimee_sousa_calepso.html">Aimee Sousa Calepso</a></li>

<li><a href="https://visvar.github.io/members/alexander_achberger.html">Alexander Achberger</a></li>

<li><a href="https://visvar.github.io/members/frank_heyen.html">Frank Heyen</a></li>

<li><a href="https://visvar.github.io/members/jonas_haischt.html">Jonas Haischt</a></li>

<li><a href="https://visvar.github.io/members/katrin_angerbauer.html">Katrin Angerbauer</a></li>

<li><a href="https://visvar.github.io/members/markus_wieland.html">Markus Wieland</a></li>

<li><a href="https://visvar.github.io/members/melissa_reinelt.html">Melissa Reinelt</a></li>

<li><a href="https://visvar.github.io/members/natalie_hube.html">Natalie Hube</a></li>

<li><a href="https://visvar.github.io/members/nina_doerr.html">Nina Dörr</a></li>

<li><a href="https://visvar.github.io/members/rene_cutura.html">Rene Cutura</a></li>

<li><a href="https://visvar.github.io/members/ruben_bauer.html">Ruben Bauer</a></li>

<li><a href="https://visvar.github.io/members/sebastian_rigling.html">Sebastian Rigling</a></li>

<li><a href="https://visvar.github.io/members/simeon_rau.html">Simeon Rau</a></li>

<li><a href="https://visvar.github.io/members/tobias_rau.html">Tobias Rau</a></li>

<li><a href="https://visvar.github.io/members/xingyao_yu.html">Xingyao Yu</a></li>

</ul>
</ul>
</nav>
</div>
</header>
</div>
    <div>
      <article><a class="anchor" name="aboutus"></a>
        <h1>Simeon Rau, M.Sc.</h1>
        <div class="aboutMember">
          <div class="avatarAndBio">
            <img class="avatar" src="../img/people/simeon_rau.jpg" />
            <div class="bio">
    <p>
      I conduct research on visualization for machine learning, mainly to support students in learning.
      Currently, I am working on visualization for music composition through human-AI collaboration.
    </p>
    </div>
          </div>
          <div class="furtherInfo">
            <div>
              <h2>Research Interests</h2>
              <ul>
                <li>Visualization &amp; visual analytics</li>
<li>Machine learning</li>
<li>HCI</li>
              </ul>
            </div>
            <div>
              <h2>Links</h2>
              <ul>
                <li><a href="https://www.visus.uni-stuttgart.de/en/institute/team/Rau-00009/" target="_blank" rel="noreferrer">University of Stuttgart website</a></li>
<li><a href="https://orcid.org/0000-0002-3124-0467" target="_blank" rel="noreferrer">ORCID</a></li>
              </ul>
            </div>
            
          </div>
        </div>
      </article>
      <article> <a class="anchor" name="publications"></a>
        <h1>Publications</h1>
        
  <h2 class="yearHeading">2022</h2>
  <div class="paper small" id="paperrau2022visualization">
    
      <img
        id="imagerau2022visualization"
        title="Click to enlarge and show details"
        onclick="toggleClass('paperrau2022visualization', 'small'); toggleImageSize(this)"
        class="publicationImage small"
        loading="lazy"
        src="../img/small/rau2022visualization.png"
      />
    <div class="metaData ">
      <h3
        onclick="toggleClass('paperrau2022visualization', 'small'); toggleImageSize(imagerau2022visualization)"
        title="Click to show details"
      >
        Visualization for AI-Assisted Composing<a class="anchor" name="rau2022visualization"></a>
      </h3>
      <div>
        Simeon Rau, Frank Heyen, Stefan Wagner, Michael Sedlmair
      </div>
      <div>
        ISMIR (2022) Full Paper
        <a href="https://visvar.github.io/pub/rau2022visualization.html" target="_blank">direct link</a>
        <a href="https://doi.org/10.5281/zenodo.7316618" target="_blank">DOI</a>
        <a href="https://ismir2022program.ismir.net/poster_217.html" target="_blank">link</a>
        <a href="../pdf/rau2022visualization.pdf" target="_blank">PDF</a>
        <a href="../video/rau2022visualization.mp4" target="_blank">video</a>
        <a href="https://github.com/visvar/vis-ai-comp" target="_blank">supplemental</a>
        <span>Best Paper Award Nomination</span>
      </div>
    </div>
    <div class="info">
      <h4>Abstract</h4><div class="abstract">We propose a visual approach for interactive, AI-assisted composition that serves as a compromise between fully automatic and fully manual composition. Instead of generating a whole piece, the AI takes on the role of an assistant that generates short melodies for the composer to choose from and adapt. In an iterative process, the composer queries the AI for continuations or alternative fill-ins, chooses a suggestion, and adds it to the piece. As listening to many suggestions would take time, we explore different ways to visualize them, to allow the composer to focus on the most interesting-looking melodies. We also present the results of a qualitative evaluation with five composers. </div>
      <h4>BibTex</h4><div class="bibtex"><textarea>@inproceedings{simeon_rau_2022_7316618,
    title        = {Visualization for AI-Assisted Composing},
    author       = {Simeon Rau and Frank Heyen and Stefan Wagner and Michael Sedlmair},
    year         = {2022},
    month        = dec,
    booktitle    = {Proceedings of the 23rd International Society for Music Information Retrieval Conference (ISMIR)},
    publisher    = {ISMIR},
    pages        = {151--159},
    doi          = {10.5281/zenodo.7316618},
    url          = {https://doi.org/10.5281/zenodo.7316618},
    venue        = {Bengaluru, India}
}
</textarea></div>
      <h4>Acknowledgements</h4><div class="abstract">This work was funded by the Cyber Valley Research Fund
and the Artificial Intelligence Software Academy (AISA).</div>
    </div>
  </div>
  
  <h2 class="yearHeading">2021</h2>
  <div class="paper small" id="paperrau2021visual">
    
      <img
        id="imagerau2021visual"
        title="Click to enlarge and show details"
        onclick="toggleClass('paperrau2021visual', 'small'); toggleImageSize(this)"
        class="publicationImage small"
        loading="lazy"
        src="../img/small/rau2021visual.png"
      />
    <div class="metaData ">
      <h3
        onclick="toggleClass('paperrau2021visual', 'small'); toggleImageSize(imagerau2021visual)"
        title="Click to show details"
      >
        Visual Support for Human-AI Co-Composition<a class="anchor" name="rau2021visual"></a>
      </h3>
      <div>
        Simeon Rau, Frank Heyen, Michael Sedlmair
      </div>
      <div>
        ISMIR (2021) Late-Breaking Demo Poster
        <a href="https://visvar.github.io/pub/rau2021visual.html" target="_blank">direct link</a>
        <a href="https://archives.ismir.net/ismir2021/latebreaking/000014.pdf" target="_blank">link</a>
        
        <a href="../pdf/rau2021visual.pdf" target="_blank">PDF</a>
        <a href="../video/rau2021visual.mp4" target="_blank">video</a>
        
        
      </div>
    </div>
    <div class="info">
      <h4>Abstract</h4><div class="abstract">We propose a visual approach for AI-assisted music composition, where the user interactively generates, selects, and adapts short melodies. Based on an entered start melody, we automatically generate multiple continuation samples. Repeating this step and in turn generating continuations for these samples results in a tree or graph of melodies. We visualize this structure with two visualizations, where nodes display the piano roll of the corresponding sample. By interacting with these visualizations, the user can quickly listen to, choose, and adapt melodies, to iteratively create a composition. A third visualization provides an overview over larger numbers of samples, allowing for insights into the AI's predictions and the sample space.</div>
      <h4>BibTex</h4><div class="bibtex"><textarea>@inproceedings{rau2021visual,
    title        = {Visual Support for Human-{AI} Co-Composition},
    author       = {Rau, Simeon and Heyen, Frank and Sedlmair, Michael},
    year         = {2021},
    booktitle    = {Extended Abstracts for the Late-Breaking Demo Session of the 22nd Int. Society for Music Information Retrieval Conf. (ISMIR)},
    url          = {https://archives.ismir.net/ismir2021/latebreaking/000014.pdf}
}
</textarea></div>
      <h4>Acknowledgements</h4><div class="abstract">This work was funded by the Cyber Valley Research Fund – Project InstruData.</div>
    </div>
  </div>
  
      </article>
    </div>
  </main>
</body>
</html>