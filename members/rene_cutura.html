<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Rene Cutura | VISVAR Research Group, University of Stuttgart</title>
    <link rel="stylesheet" href="../style.css">
    <script src="../script.js"></script>
    <link rel="shortcut icon" href="../img/favicon.png">
    <link rel="icon" type="image/png" href="../img/favicon.png" sizes="256x256">
    <link rel="apple-touch-icon" sizes="256x256" href="../img/favicon.png">
</head>
<body>
    <a class="anchor" name="top"></a>
    <main>
        <div>
            
<header>
    <div>
        <a href="https://visvar.github.io/">
            <h1 class="h1desktop">
                <div>
                    VISVAR
                </div>
                <div>
                    Research
                </div>
                <div>
                    Group
                </div>
            </h1>
            <h1 class="h1mobile">
                VISVAR
            </h1>
        </a>
    </div>
    <div>
        <nav>
            <ul>
                <li>
                    <a href="https://visvar.github.io/#aboutus">about VISVAR</a>
                </li>
                <li>
                    <a href="https://visvar.github.io/#publications">all publications</a>
                </li>
                <li class="memberNav">
                    <a href="https://visvar.github.io/#members">members</a>
                </li>
                <ul class="memberNav">
                    
                        <li>
                            <a href="https://visvar.github.io/members/aimee_sousa_calepso.html">
                                Aimee Sousa Calepso
                            </a>
                        </li>
                    
                        <li>
                            <a href="https://visvar.github.io/members/alexander_achberger.html">
                                Alexander Achberger
                            </a>
                        </li>
                    
                        <li>
                            <a href="https://visvar.github.io/members/frank_heyen.html">
                                Frank Heyen
                            </a>
                        </li>
                    
                        <li>
                            <a href="https://visvar.github.io/members/katrin_angerbauer.html">
                                Katrin Angerbauer
                            </a>
                        </li>
                    
                        <li>
                            <a href="https://visvar.github.io/members/melissa_reinelt.html">
                                Melissa Reinelt
                            </a>
                        </li>
                    
                        <li>
                            <a href="https://visvar.github.io/members/michael_sedlmair.html">
                                Michael Sedlmair
                            </a>
                        </li>
                    
                        <li>
                            <a href="https://visvar.github.io/members/natalie_hube.html">
                                Natalie Hube
                            </a>
                        </li>
                    
                        <li>
                            <a href="https://visvar.github.io/members/quynh_ngo.html">
                                Quynh Ngo
                            </a>
                        </li>
                    
                        <li>
                            <a href="https://visvar.github.io/members/rene_cutura.html">
                                Rene Cutura
                            </a>
                        </li>
                    
                        <li>
                            <a href="https://visvar.github.io/members/ruben_bauer.html">
                                Ruben Bauer
                            </a>
                        </li>
                    
                        <li>
                            <a href="https://visvar.github.io/members/xingyao_yu.html">
                                Xingyao Yu
                            </a>
                        </li>
                    
                </ul>
            </ul>
        </nav>
    </div>
</header>
        </div>
        <div>
            <article> <a class="anchor" name="aboutus"></a>
                <h1>
    Rene Cutura, M.Sc.
</h1>

<div class="aboutMember">

    <div class="avatarAndBio">
        <img class="avatar" src="../img/rene_cutura.jpg" />

        <div class="bio">
            <p>
            </p>
        </div>
    </div>

    <p>
        <a href="https://www.visus.uni-stuttgart.de/institut/team/Cutura/">Institute website</a>
    </p>

    <h2>Research Interests</h2>
    <ul>
        <li>Visualization</li>
        <li>Dimensionality reduction</li>
        <li>Data art</li>
    </ul>

    <h2>More</h2>

    <ul>
        <li>
            <a href="https://renecutura.eu/">Personal website</a>
        </li>
        <li>
            <a href="https://observablehq.com/@saehrimnir?tab=notebooks">Observable notebooks</a>
        </li>
    </ul>

</div>

            </article>
            <article> <a class="anchor" name="publications"></a>
                <h1>Publications</h1>
                
    <div
        class="paper small"
        id="paperrijken2021illegible"
    >
        <h2
           onclick="toggleClass('paperrijken2021illegible', 'small'); toggleImageSize(imagerijken2021illegible);"
        >
            Illegible Semantics: Exploring the Design Space of Metal Logos
        </h2>
        
            <img
                id="imagerijken2021illegible"
                onclick="toggleClass('paperrijken2021illegible', 'small'); toggleImageSize(this);"
                class="publicationImage small"
                src="../img/small/rijken2021illegible.png"
            />
        <div class="metaData ">
            <div class="authors">
                <span class="firstAuthor">Gerrit J. Rijken</span>,
                Rene Cutura, Frank Heyen, Michael Sedlmair, Michael Correll, Jason Dykes, Noeska Smit
            </div>
            <div>
                <span class="publication">alt.VIS 2021</span>
                
                <a href="https://arxiv.org/ftp/arxiv/papers/2109/2109.01688.pdf" target="_blank">PDF</a>
                <a href="https://arxiv.org/abs/2109.01688" target="_blank">publisher website</a>
                <a href="https://www.youtube.com/watch?v=BZOdIhU-mrA" target="_blank">video</a>
                <a href="http://illegiblesemantics.com" target="_blank">supplemental material</a>
            </div>
        </div>
        <div class="info">
            <h4>Abstract</h4>
            <div class="abstract">
                The logos of metal bands can be by turns gaudy, uncouth, or nearly illegible. Yet, these logos work: they communicate sophisticated notions of genre and emotional affect. In this paper we use the design considerations of metal logos to explore the space of “illegible semantics”: the ways that text can communicate information at the cost of readability, which is not always the most important objective. In this work, drawing on formative visualization theory, professional design expertise, and empirical assessments of a corpus ofmetal band logos, we describe a design space of metal logos and present a tool through which logo characteristics can be explored through visualization. We investigate ways in which logo designers imbue their text with meaning and consider opportunities and implications for visualization more widely.
            </div>
            
            <h4>BibTex</h4>
            <div class="bibtex">
                <textarea>@misc{rijken2021illegible,
      title={Illegible Semantics: Exploring the Design Space of Metal Logos}, 
      author={Gerrit J. Rijken and Rene Cutura and Frank Heyen and Michael Sedlmair and Michael Correll and Jason Dykes and Noeska Smit},
      year={2021},
      eprint={2109.01688},
      archivePrefix={arXiv},
      primaryClass={cs.HC}
}</textarea>
            </div>
            
        </div>
    </div>
    
    <div
        class="paper small"
        id="papermorariu2021dumbledr"
    >
        <h2
           onclick="toggleClass('papermorariu2021dumbledr', 'small'); toggleImageSize(imagemorariu2021dumbledr);"
        >
            DumbleDR: Predicting User Preferences of Dimensionality Reduction Projection Quality
        </h2>
        
        <div class="metaData noImage">
            <div class="authors">
                <span class="firstAuthor">Cristina Morariu</span>,
                Adrien Bibal, Rene Cutura, Benoît Frénay, Michael Sedlmair
            </div>
            <div>
                <span class="publication">arXiv 2021</span>
                
                <a href="https://arxiv.org/pdf/2105.09275.pdf" target="_blank">PDF</a>
                <a href="https://arxiv.org/abs/2105.09275" target="_blank">publisher website</a>
                
                
            </div>
        </div>
        <div class="info">
            <h4>Abstract</h4>
            <div class="abstract">
                A plethora of dimensionality reduction techniques have emerged over the past decades, leaving researchers and analysts with a wide variety of choices for reducing their data, all the more so given some techniques come with additional parametrization (e.g. t-SNE, UMAP, etc.). Recent studies are showing that people often use dimensionality reduction as a black-box regardless of the specific properties the method itself preserves. Hence, evaluating and comparing 2D projections is usually qualitatively decided, by setting projections side-by-side and letting human judgment decide which projection is the best. In this work, we propose a quantitative way of evaluating projections, that nonetheless places human perception at the center. We run a comparative study, where we ask people to select 'good' and 'misleading' views between scatterplots of low-level projections of image datasets, simulating the way people usually select projections. We use the study data as labels for a set of quality metrics whose purpose is to discover and quantify what exactly people are looking for when deciding between projections. With this proxy for human judgments, we use it to rank projections on new datasets, explain why they are relevant, and quantify the degree of subjectivity in projections selected.
            </div>
            
            
        </div>
    </div>
    
    <div
        class="paper small"
        id="papercutura2020druidjs"
    >
        <h2
           onclick="toggleClass('papercutura2020druidjs', 'small'); toggleImageSize(imagecutura2020druidjs);"
        >
            DRUIDJS — A JavaScript Library for Dimensionality Reduction
        </h2>
        
            <img
                id="imagecutura2020druidjs"
                onclick="toggleClass('papercutura2020druidjs', 'small'); toggleImageSize(this);"
                class="publicationImage small"
                src="../img/small/cutura2020druidjs.png"
            />
        <div class="metaData ">
            <div class="authors">
                <span class="firstAuthor">Rene Cutura</span>,
                Christoph Kralj, Michael Sedlmair
            </div>
            <div>
                <span class="publication">VIS 2020</span>
                <span class="publication">Short Paper</span>
                <a href="../pdf/cutura2020druidjs.pdf" target="_blank">PDF</a>
                <a href="https://ieeexplore.ieee.org/abstract/document/9331283" target="_blank">publisher website</a>
                <a href="https://youtu.be/LyiqHl4rq34" target="_blank">video</a>
                <a href="https://renecutura.eu/pdfs/Druid_Supp.pdf" target="_blank">supplemental material</a>
            </div>
        </div>
        <div class="info">
            <h4>Abstract</h4>
            <div class="abstract">
                Dimensionality reduction (DR) is a widely used technique for visualization. Nowadays, many of these visualizations are developed for the web, most commonly using JavaScript as the underlying programming language. So far, only few DR methods have a JavaScript implementation though, necessitating developers to write wrappers around implementations in other languages. In addition, those DR methods that exist in JavaScript libraries, such as PCA, t-SNE, and UMAP, do not offer consistent programming interfaces, hampering the quick integration of different methods. Toward a coherent and comprehensive DR programming framework, we developed an open source JavaScript library named DruidJS. Our library contains implementations of ten different DR algorithms, as well as the required linear algebra techniques, tools, and utilities.
            </div>
            
            <h4>BibTex</h4>
            <div class="bibtex">
                <textarea>@inproceedings{cutura2020druid,
  title={{DRUIDJS — A JavaScript Library for Dimensionality Reduction}},
  author={Cutura, Rene and Kralj, Christoph and Sedlmair, Michael},
  booktitle={2020 IEEE Visualization Conference (VIS)},
  pages={111--115},
  year={2020},
  organization={IEEE}
}</textarea>
            </div>
            
            <h4>Acknowledgements</h4>
            <div class="abstract">
                This work was supported by the BMVIT ICT of the Future program via the ViSciPub project (no. 867378) and handled by the FFG.
            </div>
        </div>
    </div>
    
    <div
        class="paper small"
        id="papercutura2020comparing"
    >
        <h2
           onclick="toggleClass('papercutura2020comparing', 'small'); toggleImageSize(imagecutura2020comparing);"
        >
            Comparing and Exploring High-Dimensional Data with Dimensionality Reduction Algorithms and Matrix Visualizations
        </h2>
        
            <img
                id="imagecutura2020comparing"
                onclick="toggleClass('papercutura2020comparing', 'small'); toggleImageSize(this);"
                class="publicationImage small"
                src="../img/small/cutura2020comparing.png"
            />
        <div class="metaData ">
            <div class="authors">
                <span class="firstAuthor">Rene Cutura</span>,
                Michaël Aupetit, Jean-Daniel Fekete, Michael Sedlmair
            </div>
            <div>
                <span class="publication">AVI  2020</span>
                <span class="publication">Full Paper</span>
                <a href="../pdf/cutura2020comparing.pdf" target="_blank">PDF</a>
                <a href="https://dl.acm.org/doi/abs/10.1145/3399715.3399875" target="_blank">publisher website</a>
                <a href="https://youtu.be/UPkH7rc0ulU" target="_blank">video</a>
                
            </div>
        </div>
        <div class="info">
            <h4>Abstract</h4>
            <div class="abstract">
                We propose Compadre, a tool for visual analysis for comparing distances of high-dimensional (HD) data and their low-dimensional projections. At the heart is a matrix visualization to represent the discrepancy between distance matrices, linked side-by-side with 2D scatterplot projections of the data. Using different examples and datasets, we illustrate how this approach fosters (1) evaluating dimensionality reduction techniques w.r.t. how well they project the HD data, (2) comparing them to each other side-by-side, and (3) evaluate important data features through subspace comparison. We also present a case study, in which we analyze IEEE VIS authors from 1990 to 2018, and gain new insights on the relationships between coauthors, citations, and keywords. The coauthors are projected as accurately with UMAP as with t-SNE but the projections show different insights. The structure of the citation subspace is very different from the coauthor subspace. The keyword subspace is noisy yet consistent among the three IEEE VIS sub-conferences.
            </div>
            
            <h4>BibTex</h4>
            <div class="bibtex">
                <textarea>@inproceedings{cutura2020comparing,
  title={Comparing and exploring high-dimensional data with dimensionality reduction algorithms and matrix visualizations},
  author={Cutura, Rene and Aupetit, Micha{\"e}l and Fekete, Jean-Daniel and Sedlmair, Michael},
  booktitle={Proc. Intl. Conf. on Advanced Visual Interfaces (AVI)},
  pages={1--9},
  year={2020},
  doi={10.1145/3399715.3399875}}</textarea>
            </div>
            
            <h4>Acknowledgements</h4>
            <div class="abstract">
                This work was supported by the BMVIT ICT of the Future program via the ViSciPub project (no. 867378) and handled by the FFG.
            </div>
        </div>
    </div>
    
    <div
        class="paper small"
        id="paperachberger2020caarvida"
    >
        <h2
           onclick="toggleClass('paperachberger2020caarvida', 'small'); toggleImageSize(imageachberger2020caarvida);"
        >
            Caarvida: Visual Analytics for Test Drive Videos
        </h2>
        
        <div class="metaData noImage">
            <div class="authors">
                <span class="firstAuthor">Alexander Achberger</span>,
                Rene Cutura, Oguzhan Türksoy, Michael Sedlmair
            </div>
            <div>
                <span class="publication">AVI  2020</span>
                <span class="publication">Full Paper</span>
                
                <a href="https://dl.acm.org/doi/abs/10.1145/3399715.3399862" target="_blank">publisher website</a>
                
                
            </div>
        </div>
        <div class="info">
            <h4>Abstract</h4>
            <div class="abstract">
                We report on an interdisciplinary visual analytics project wherein automotive engineers analyze test drive videos. These videos are annotated with navigation-specific augmented reality (AR) content, and the engineers need to identify issues and evaluate the behavior of the underlying AR navigation system. With the increasing amount of video data, traditional analysis approaches can no longer be conducted in an acceptable timeframe. To address this issue, we collaboratively developed Caarvida, a visual analytics tool that helps engineers to accomplish their tasks faster and handle an increased number of videos. Caarvida combines automatic video analysis with interactive and visual user interfaces. We conducted two case studies which show that Caarvida successfully supports domain experts and speeds up their task completion time.
            </div>
            
            
        </div>
    </div>
    
    <div
        class="paper small"
        id="papercutura2018viscoder"
    >
        <h2
           onclick="toggleClass('papercutura2018viscoder', 'small'); toggleImageSize(imagecutura2018viscoder);"
        >
            VisCoDeR: A Tool for Visually Comparing Dimensionality Reduction Algorithms
        </h2>
        
            <img
                id="imagecutura2018viscoder"
                onclick="toggleClass('papercutura2018viscoder', 'small'); toggleImageSize(this);"
                class="publicationImage small"
                src="../img/small/cutura2018viscoder.png"
            />
        <div class="metaData ">
            <div class="authors">
                <span class="firstAuthor">Rene Cutura</span>,
                Stefan Holzer, Michaël Aupetit, Michael Sedlmair
            </div>
            <div>
                <span class="publication">ESANN 2018</span>
                <span class="publication">Full Paper</span>
                <a href="../pdf/cutura2018viscoder.pdf" target="_blank">PDF</a>
                <a href="" target="_blank">publisher website</a>
                <a href="https://youtu.be/gg2pgv0xwmc" target="_blank">video</a>
                
            </div>
        </div>
        <div class="info">
            <h4>Abstract</h4>
            <div class="abstract">
                We propose VisCoDeR, a tool that leverages comparative visualization to support learning and analyzing different dimensionality reduction (DR) methods. VisCoDeR fosters two modes. The Discover mode allows qualitatively comparing several DR results by juxtaposing and linking the resulting scatterplots. The Explore mode allows for analyzing hundreds of differently parameterized DR results in a quantitative way. We present use cases that show that our approach helps to understand similarities and differences between DR algorithms.
            </div>
            
            <h4>BibTex</h4>
            <div class="bibtex">
                <textarea>@inproceedings{cutura2018viscoder,
  title={{VisCoDeR: A Tool for Visually Comparing Dimensionality Reduction Algorithms}},
  author={Cutura, Rene and Holzer, Stefan and Aupetit, Micha{\"e}l and Sedlmair, Michael},
  booktitle={Euro. Symp. on Artificial Neural Networks, Computational Intelligence and Machine Learning (ESANN)},
  pages={641--646}
  year={2018}
}</textarea>
            </div>
            
        </div>
    </div>
    
            </article>
        </div>
    </main>
</body>
</html>