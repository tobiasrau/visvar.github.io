<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Rene Cutura | VISVAR Research Group, University of Stuttgart</title>
  <link rel="stylesheet" href="../style.css">
  <script src="../script.js"></script>
  <link rel="shortcut icon" href="../img/favicon.png">
  <link rel="icon" type="image/png" href="../img/favicon.png" sizes="256x256">
  <link rel="apple-touch-icon" sizes="256x256" href="../img/favicon.png">
</head>
<body>
  <a class="anchor" name="top"></a>
  <main>
    <div>
      
<header>
  <div>
    <a href="https://visvar.github.io/">
      <h1 class="h1desktop"><div>VISVAR</div><div>Research</div><div>Group</div></h1>
      <h1 class="h1mobile">VISVAR</h1>
    </a>
  </div>
  <div>
    <nav>
      <ul>
        <li>
          <a href="https://visvar.github.io/#aboutus">about VISVAR</a>
        </li>
        <li>
          <a href="https://visvar.github.io/#publications">publications</a>
        </li>
        <li class="memberNav">
          <a href="https://visvar.github.io/#members">members</a>
        </li>
        <ul class="memberNav">
          
            <li><a href="https://visvar.github.io/members/aimee_sousa_calepso.html">Aimee Sousa Calepso</a></li>
          
            <li><a href="https://visvar.github.io/members/alexander_achberger.html">Alexander Achberger</a></li>
          
            <li><a href="https://visvar.github.io/members/frank_heyen.html">Frank Heyen</a></li>
          
            <li><a href="https://visvar.github.io/members/jonas_haischt.html">Jonas Haischt</a></li>
          
            <li><a href="https://visvar.github.io/members/katrin_angerbauer.html">Katrin Angerbauer</a></li>
          
            <li><a href="https://visvar.github.io/members/melissa_reinelt.html">Melissa Reinelt</a></li>
          
            <li><a href="https://visvar.github.io/members/michael_sedlmair.html">Michael Sedlmair</a></li>
          
            <li><a href="https://visvar.github.io/members/natalie_hube.html">Natalie Hube</a></li>
          
            <li><a href="https://visvar.github.io/members/quynh_ngo.html">Quynh Ngo</a></li>
          
            <li><a href="https://visvar.github.io/members/rene_cutura.html">Rene Cutura</a></li>
          
            <li><a href="https://visvar.github.io/members/ruben_bauer.html">Ruben Bauer</a></li>
          
            <li><a href="https://visvar.github.io/members/sebastian_rigling.html">Sebastian Rigling</a></li>
          
            <li><a href="https://visvar.github.io/members/simeon_rau.html">Simeon Rau</a></li>
          
            <li><a href="https://visvar.github.io/members/xingyao_yu.html">Xingyao Yu</a></li>
          
        </ul>
      </ul>
    </nav>
  </div>
</header>
    </div>
    <div>
      <article> <a class="anchor" name="aboutus"></a>
        <h1>
  Rene Cutura, M.Sc.
</h1>

<div class="aboutMember">

  <div class="avatarAndBio">
    <img class="avatar" src="../img/people/rene_cutura.jpg" />

    <div class="bio">
      <p>
        My research focuses on visualization for dimensionality reduction, especially the comparison between
        different techniques.
        I developed and maintain two open source JavaScript libraries for dimensionality reduction
        (<a href="https://github.com/saehm/DruidJS" target="_blank">DruidJS</a>) and scatterplot gridification
        (<a href="https://github.com/saehm/hagrid" target="_blank">Hagrid</a>).
        Besides more serious research, I occasionally explore ways to create <a
          href="https://observablehq.com/@saehrimnir/visap21" target="_blank">data art</a> as well.
      </p>
    </div>
  </div>

  <p>
    <a href="https://www.visus.uni-stuttgart.de/institut/team/Cutura/" target="_blank">Institute website</a>
  </p>

  <h2>Research Interests</h2>
  <ul>
    <li>Visualization</li>
    <li>Dimensionality reduction</li>
    <li>Data art</li>
  </ul>

  <h2>More</h2>

  <ul>
    <li>
      <a href="https://renecutura.eu/" target="_blank">Personal website</a>
    </li>
    <li>
      <a href="https://observablehq.com/@saehrimnir?tab=notebooks" target="_blank">Observable notebooks</a>
    </li>
    <li>
      <a href="https://orcid.org/0000-0003-0395-2448" target="_blank">ORCID</a>
    </li>
  </ul>

</div>

      </article>
      <article> <a class="anchor" name="publications"></a>
        <h1>Publications</h1>
        
  
  <h2>2022</h2>
  
  <div class="paper small" id="paperangerbauer2022accessibility">
    
      <img
        id="imageangerbauer2022accessibility"
        title="Click to enlarge and show details"
        onclick="toggleClass('paperangerbauer2022accessibility', 'small'); toggleImageSize(this)"
        class="publicationImage small"
        src="../img/small/angerbauer2022accessibility.png"
      />
    <div class="metaData ">
      <h3
        onclick="toggleClass('paperangerbauer2022accessibility', 'small'); toggleImageSize(imageangerbauer2022accessibility)"
        title="Click to show details"
      >
        Accessibility for Color Vision Deficiencies: Challenges and Findings of a Large Scale Study on Paper Figures<a class="anchor" name="angerbauer2022accessibility"></a>
      </h3>
      <div>
        Katrin Angerbauer, Nils Rodrigues, Rene Cutura, Seyda Öney, Nelusa Pathmanathan, Cristina Morariu, Daniel Weiskopf, Michael Sedlmair
      </div>
      <div>
        CHI (2022) Full Paper
        <a href="https://doi.org/10.1145/3491102.3502133" target="_blank">website</a>
        <a href="../pdf/angerbauer2022accessibility.pdf" target="_blank">PDF</a>
        
        
      </div>
    </div>
    <div class="info">
      <h4>Abstract</h4><div class="abstract">We present an exploratory study on the accessibility of images in publications when viewed with color vision deficiencies (CVDs). The study is based on 1,710 images sampled from a visualization dataset (VIS30K) over five years. We simulated four CVDs on each image. First, four researchers (one with a CVD) identified existing issues and helpful aspects in a subset of the images. Based on the resulting labels, 200 crowdworkers provided  30,000 ratings on present CVD issues in the simulated images. We analyzed this data for correlations, clusters, trends, and free text comments to gain a first overview of paper figure accessibility. Overall, about 60 % of the images were rated accessible. Furthermore, our study indicates that accessibility issues are subjective and hard to detect. On a meta-level, we reflect on our study experience to point out challenges and opportunities of large-scale accessibility studies for future research directions.</div>
      <h4>BibTex</h4><div class="bibtex"><textarea>@inproceedings{10.1145/3491102.3502133,
author = {Angerbauer, Katrin and Rodrigues, Nils and Cutura, Rene and \"{O}ney, Seyda and Pathmanathan, Nelusa and Morariu, Cristina and Weiskopf, Daniel and Sedlmair, Michael},
title = {Accessibility for Color Vision Deficiencies: Challenges and Findings of a Large Scale Study on Paper Figures},
year = {2022},
isbn = {9781450391573},
publisher = {ACM},
url = {https://doi.org/10.1145/3491102.3502133},
doi = {10.1145/3491102.3502133},
abstract = {We present an exploratory study on the accessibility of images in publications when viewed with color vision deficiencies (CVDs). The study is based on 1,710 images sampled from a visualization dataset (VIS30K) over five years. We simulated four CVDs on each image. First, four researchers (one with a CVD) identified existing issues and helpful aspects in a subset of the images. Based on the resulting labels, 200 crowdworkers provided  30,000 ratings on present CVD issues in the simulated images. We analyzed this data for correlations, clusters, trends, and free text comments to gain a first overview of paper figure accessibility. Overall, about 60 % of the images were rated accessible. Furthermore, our study indicates that accessibility issues are subjective and hard to detect. On a meta-level, we reflect on our study experience to point out challenges and opportunities of large-scale accessibility studies for future research directions. },
booktitle = {CHI Conference on Human Factors in Computing Systems},
articleno = {134},
numpages = {23},
keywords = {color vision deficiency, crowdsourcing, visualization, accessibility},
series = {CHI '22}
}</textarea></div>
      <h4>Acknowledgements</h4><div class="abstract">Funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) – Project-ID 251654672 – TRR 161 (projects A08 and B01). We thank all our study participants and in particular Sajid Baloch for his valuable input.</div>
    </div>
  </div>
  
  
  <h2>2021</h2>
  
  <div class="paper small" id="papercutura2021visap">
    
      <img
        id="imagecutura2021visap"
        title="Click to enlarge and show details"
        onclick="toggleClass('papercutura2021visap', 'small'); toggleImageSize(this)"
        class="publicationImage small"
        src="../img/small/cutura2021visap.png"
      />
    <div class="metaData ">
      <h3
        onclick="toggleClass('papercutura2021visap', 'small'); toggleImageSize(imagecutura2021visap)"
        title="Click to show details"
      >
        DaRt: Generative Art using Dimensionality Reduction Algorithms<a class="anchor" name="cutura2021visap"></a>
      </h3>
      <div>
        Rene Cutura, Kathrin Angerbauer, Frank Heyen, Natalie Hube, Michael Sedlmair
      </div>
      <div>
        VIS (2021) Pictorial
        <a href="https://doi.org/10.1109/VISAP52981.2021.00013" target="_blank">website</a>
        <a href="../pdf/cutura2021visap.pdf" target="_blank">PDF</a>
        <a href="https://youtu.be/pOcksJOiAPw" target="_blank">video</a>
        
      </div>
    </div>
    <div class="info">
      <h4>Abstract</h4><div class="abstract">Dimensionality Reduction (DR) is a popular technique that is often used in Machine Learning and Visualization communities to analyze high-dimensional data. The approach is empirically proven to be powerful for uncovering previously unseen structures in the data. While observing the results of the intermediate optimization steps of DR algorithms, we coincidently discovered the artistic beauty of the DR process. With enthusiasm for the beauty, we decided to look at DR from a generative art lens rather than their technical application aspects and use DR techniques to create artwork. Particularly, we use the optimization process to generate images, by drawing each intermediate step of the optimization process with some opacity over the previous intermediate result. As another alternative input, we used a neural-network model for face-landmark detection, to apply DR to portraits, while maintaining some facial properties, resulting in abstracted facial avatars. In this work, we provide such a collection of such artwork.</div>
      <h4>BibTex</h4><div class="bibtex"><textarea>@inproceedings{cutura2021dart,
  title={{DaRt}: Generative Art using Dimensionality Reduction Algorithms},
  author={Cutura, Rene and Angerbauer, Katrin and Heyen, Frank and Hube, Natalie and Sedlmair, Michael},
  booktitle={2021 IEEE VIS Arts Program (VISAP)},
  pages={59--72},
  year={2021},
  organization={IEEE},
}</textarea></div>
      <h4>Acknowledgements</h4><div class="abstract">Funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) - Project-ID 251654672 - TRR 161</div>
    </div>
  </div>
  
  
  <div class="paper small" id="papercutura2021vinci">
    
      <img
        id="imagecutura2021vinci"
        title="Click to enlarge and show details"
        onclick="toggleClass('papercutura2021vinci', 'small'); toggleImageSize(this)"
        class="publicationImage small"
        src="../img/small/cutura2021vinci.png"
      />
    <div class="metaData ">
      <h3
        onclick="toggleClass('papercutura2021vinci', 'small'); toggleImageSize(imagecutura2021vinci)"
        title="Click to show details"
      >
        Hagrid — Gridify Scatterplots with Hilbert and Gosper Curves<a class="anchor" name="cutura2021vinci"></a>
      </h3>
      <div>
        Rene Cutura, 
Cristina Morariu, Zhanglin Cheng, Yunhai Wang, Daniel Weiskopf, Michael Sedlmair
      </div>
      <div>
        VINCI (2021) Full Paper
        <a href="https://doi.org/10.1145/3481549.3481569" target="_blank">website</a>
        <a href="../pdf/cutura2021vinci.pdf" target="_blank">PDF</a>
        <a href="https://youtu.be/E_XP31_JzGY" target="_blank">video</a>
        <a href="https://renecutura.eu/pdfs/hagrid_supplemental.pdf" target="_blank">supplemental</a>
      </div>
    </div>
    <div class="info">
      <h4>Abstract</h4><div class="abstract">A common enhancement of scatterplots represents points as small multiples, glyphs, or thumbnail images. As this encoding often results in overlaps, a general strategy is to alter the position of the data points, for instance, to a grid-like structure. Previous approaches rely on solving expensive optimization problems or on dividing the space that alter the global structure of the scatterplot. To find a good balance between efficiency and neighborhood and layout preservation, we propose Hagrid, a technique that uses space-filling curves (SFCs) to “gridify” a scatterplot without employing expensive collision detection and handling mechanisms. Using SFCs ensures that the points are plotted close to their original position, retaining approximately the same global structure. The resulting scatterplot is mapped onto a rectangular or hexagonal grid, using Hilbert and Gosper curves. We discuss and evaluate the theoretic runtime of our approach and quantitatively compare our approach to three state-of-the-art gridifying approaches, DGrid, Small multiples with gaps SMWG, and CorrelatedMultiples CMDS, in an evaluation comprising 339 scatterplots. Here, we compute several quality measures for neighborhood preservation together with an analysis of the actual runtimes. The main results show that, compared to the best other technique, Hagrid is faster by a factor of four, while achieving similar or even better quality of the gridified layout. Due to its computational efficiency, our approach also allows novel applications of gridifying approaches in interactive settings, such as removing local overlap upon hovering over a scatterplot.</div>
      <h4>BibTex</h4><div class="bibtex"><textarea>@inproceedings{cutura2021hagrid,
	author = {Cutura, Rene and Morariu, Cristina and Cheng, Zhanglin and Wang, Yunhai and Weiskopf, Daniel and Sedlmair, Michael},
	title = {{Hagrid -- Gridify Scatterplots with Hilbert and Gosper Curves}},
	year = {2021},
	isbn = {9781450386470},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3481549.3481569},
	doi = {10.1145/3481549.3481569},
	booktitle = {The 14th International Symposium on Visual Information Communication and Interaction},
	articleno = {1},
	numpages = {8},
	keywords = {Grid layout, Neighborhood-preserving., Space-filling curve},
	location = {Potsdam, Germany},
	series = {VINCI 2021}
}</textarea></div>
      <h4>Acknowledgements</h4><div class="abstract">This work was supported by the BMK FFG ICT of the Future program via the ViSciPub project (no. 867378), and by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) – Project-ID 251654672 – TRR 161.</div>
    </div>
  </div>
  
  
  <div class="paper small" id="paperrijken2021illegible">
    
      <img
        id="imagerijken2021illegible"
        title="Click to enlarge and show details"
        onclick="toggleClass('paperrijken2021illegible', 'small'); toggleImageSize(this)"
        class="publicationImage small"
        src="../img/small/rijken2021illegible.png"
      />
    <div class="metaData ">
      <h3
        onclick="toggleClass('paperrijken2021illegible', 'small'); toggleImageSize(imagerijken2021illegible)"
        title="Click to show details"
      >
        Illegible Semantics: Exploring the Design Space of Metal Logos<a class="anchor" name="rijken2021illegible"></a>
      </h3>
      <div>
        Gerrit J. Rijken, Rene Cutura, Frank Heyen, Michael Sedlmair, Michael Correll, Jason Dykes, Noeska Smit
      </div>
      <div>
        alt.VIS (2021) Workshop Paper
        <a href="https://doi.org/10.48550/arXiv.2109.01688" target="_blank">website</a>
        <a href="https://arxiv.org/ftp/arxiv/papers/2109/2109.01688.pdf" target="_blank">PDF</a>
        <a href="https://www.youtube.com/watch?v=BZOdIhU-mrA" target="_blank">video</a>
        <a href="http://illegiblesemantics.com" target="_blank">supplemental</a>
      </div>
    </div>
    <div class="info">
      <h4>Abstract</h4><div class="abstract">The logos of metal bands can be by turns gaudy, uncouth, or nearly illegible. Yet, these logos work: they communicate sophisticated notions of genre and emotional affect. In this paper we use the design considerations of metal logos to explore the space of “illegible semantics”: the ways that text can communicate information at the cost of readability, which is not always the most important objective. In this work, drawing on formative visualization theory, professional design expertise, and empirical assessments of a corpus ofmetal band logos, we describe a design space of metal logos and present a tool through which logo characteristics can be explored through visualization. We investigate ways in which logo designers imbue their text with meaning and consider opportunities and implications for visualization more widely.</div>
      <h4>BibTex</h4><div class="bibtex"><textarea>@inproceedings{rijken2021altvis,
	Author = {Gerrit J Rijken and Rene Cutura and Frank Heyen and Michael Sedlmair and Michael Correll and Jason Dykes and Noeska Smit},
	Title = {Illegible Semantics: Exploring the Design Space of Metal Logos},
	Booktitle = {{IEEE VIS} alt.VIS Workshop},
	url = {https://arxiv.org/abs/2109.01688},
	Year = {2021}
}</textarea></div>
      
    </div>
  </div>
  
  
  <div class="paper small" id="papermorariu2021arxiv">
    
      <img
        id="imagemorariu2021arxiv"
        title="Click to enlarge and show details"
        onclick="toggleClass('papermorariu2021arxiv', 'small'); toggleImageSize(this)"
        class="publicationImage small"
        src="../img/small/morariu2021arxiv.png"
      />
    <div class="metaData ">
      <h3
        onclick="toggleClass('papermorariu2021arxiv', 'small'); toggleImageSize(imagemorariu2021arxiv)"
        title="Click to show details"
      >
        DumbleDR: Predicting User Preferences of Dimensionality Reduction Projection Quality<a class="anchor" name="morariu2021arxiv"></a>
      </h3>
      <div>
        Cristina Morariu, Adrien Bibal, Rene Cutura, Benoît Frénay, Michael Sedlmair
      </div>
      <div>
        arXiv (2021) 
        <a href="https://doi.org/10.48550/arXiv.2105.09275" target="_blank">website</a>
        <a href="https://arxiv.org/pdf/2105.09275.pdf" target="_blank">PDF</a>
        
        
      </div>
    </div>
    <div class="info">
      <h4>Abstract</h4><div class="abstract">A plethora of dimensionality reduction techniques have emerged over the past decades, leaving researchers and analysts with a wide variety of choices for reducing their data, all the more so given some techniques come with additional parametrization (e.g. t-SNE, UMAP, etc.). Recent studies are showing that people often use dimensionality reduction as a black-box regardless of the specific properties the method itself preserves. Hence, evaluating and comparing 2D projections is usually qualitatively decided, by setting projections side-by-side and letting human judgment decide which projection is the best. In this work, we propose a quantitative way of evaluating projections, that nonetheless places human perception at the center. We run a comparative study, where we ask people to select 'good' and 'misleading' views between scatterplots of low-level projections of image datasets, simulating the way people usually select projections. We use the study data as labels for a set of quality metrics whose purpose is to discover and quantify what exactly people are looking for when deciding between projections. With this proxy for human judgments, we use it to rank projections on new datasets, explain why they are relevant, and quantify the degree of subjectivity in projections selected.</div>
      <h4>BibTex</h4><div class="bibtex"><textarea>@techreport{morariu2021arxiv,
	title = {{DumbleDR}: Predicting User Preferences of Dimensionality Reduction Projection Quality},
	author = {Cristina Morariu and Adrien Bibal and Rene Cutura and Benoit Frenay and Michael Sedlmair},
	Institution = {{arXiv} preprint},
	Number = {arXiv:2105.09275},
	Type = {Technical Report},
	url = {https://arxiv.org/abs/2105.09275},
	Year = {2021}
}</textarea></div>
      
    </div>
  </div>
  
  
  <h2>2020</h2>
  
  <div class="paper small" id="papercutura2020druidjs">
    
      <img
        id="imagecutura2020druidjs"
        title="Click to enlarge and show details"
        onclick="toggleClass('papercutura2020druidjs', 'small'); toggleImageSize(this)"
        class="publicationImage small"
        src="../img/small/cutura2020druidjs.png"
      />
    <div class="metaData ">
      <h3
        onclick="toggleClass('papercutura2020druidjs', 'small'); toggleImageSize(imagecutura2020druidjs)"
        title="Click to show details"
      >
        DRUIDJS — A JavaScript Library for Dimensionality Reduction<a class="anchor" name="cutura2020druidjs"></a>
      </h3>
      <div>
        Rene Cutura, Christoph Kralj, Michael Sedlmair
      </div>
      <div>
        VIS (2020) Short Paper
        <a href="https://doi.org/10.1109/VIS47514.2020.00029" target="_blank">website</a>
        <a href="../pdf/cutura2020druidjs.pdf" target="_blank">PDF</a>
        <a href="https://youtu.be/LyiqHl4rq34" target="_blank">video</a>
        <a href="https://renecutura.eu/pdfs/Druid_Supp.pdf" target="_blank">supplemental</a>
      </div>
    </div>
    <div class="info">
      <h4>Abstract</h4><div class="abstract">Dimensionality reduction (DR) is a widely used technique for visualization. Nowadays, many of these visualizations are developed for the web, most commonly using JavaScript as the underlying programming language. So far, only few DR methods have a JavaScript implementation though, necessitating developers to write wrappers around implementations in other languages. In addition, those DR methods that exist in JavaScript libraries, such as PCA, t-SNE, and UMAP, do not offer consistent programming interfaces, hampering the quick integration of different methods. Toward a coherent and comprehensive DR programming framework, we developed an open source JavaScript library named DruidJS. Our library contains implementations of ten different DR algorithms, as well as the required linear algebra techniques, tools, and utilities.</div>
      <h4>BibTex</h4><div class="bibtex"><textarea>@inproceedings{cutura2020druid,
  title={{DRUIDJS — A JavaScript Library for Dimensionality Reduction}},
  author={Cutura, Rene and Kralj, Christoph and Sedlmair, Michael},
  booktitle={2020 IEEE Visualization Conference (VIS)},
  pages={111--115},
  year={2020},
  organization={IEEE}
}</textarea></div>
      <h4>Acknowledgements</h4><div class="abstract">This work was supported by the BMVIT ICT of the Future program via the ViSciPub project (no. 867378) and handled by the FFG.</div>
    </div>
  </div>
  
  
  <div class="paper small" id="paperachberger2020caarvida">
    
      <img
        id="imageachberger2020caarvida"
        title="Click to enlarge and show details"
        onclick="toggleClass('paperachberger2020caarvida', 'small'); toggleImageSize(this)"
        class="publicationImage small"
        src="../img/small/achberger2020caarvida.png"
      />
    <div class="metaData ">
      <h3
        onclick="toggleClass('paperachberger2020caarvida', 'small'); toggleImageSize(imageachberger2020caarvida)"
        title="Click to show details"
      >
        Caarvida: Visual Analytics for Test Drive Videos<a class="anchor" name="achberger2020caarvida"></a>
      </h3>
      <div>
        Alexander Achberger, Rene Cutura, Oguzhan Türksoy, Michael Sedlmair
      </div>
      <div>
        AVI  (2020) Full Paper
        <a href="https://doi.org/10.1145/3399715.3399862" target="_blank">website</a>
        <a href="../pdf/achberger2020caarvida.pdf" target="_blank">PDF</a>
        
        
      </div>
    </div>
    <div class="info">
      <h4>Abstract</h4><div class="abstract">We report on an interdisciplinary visual analytics project wherein automotive engineers analyze test drive videos. These videos are annotated with navigation-specific augmented reality (AR) content, and the engineers need to identify issues and evaluate the behavior of the underlying AR navigation system. With the increasing amount of video data, traditional analysis approaches can no longer be conducted in an acceptable timeframe. To address this issue, we collaboratively developed Caarvida, a visual analytics tool that helps engineers to accomplish their tasks faster and handle an increased number of videos. Caarvida combines automatic video analysis with interactive and visual user interfaces. We conducted two case studies which show that Caarvida successfully supports domain experts and speeds up their task completion time.</div>
      <h4>BibTex</h4><div class="bibtex"><textarea>@inproceedings{10.1145/3399715.3399862,
author = {Achberger, Alexander and Cutura, Ren\'{e} and T\"{u}rksoy, Oguzhan and Sedlmair, Michael},
title = {Caarvida: Visual Analytics for Test Drive Videos},
year = {2020},
isbn = {9781450375351},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3399715.3399862},
doi = {10.1145/3399715.3399862},
abstract = {We report on an interdisciplinary visual analytics project wherein automotive engineers analyze test drive videos. These videos are annotated with navigation-specific augmented reality (AR) content, and the engineers need to identify issues and evaluate the behavior of the underlying AR navigation system. With the increasing amount of video data, traditional analysis approaches can no longer be conducted in an acceptable timeframe. To address this issue, we collaboratively developed Caarvida, a visual analytics tool that helps engineers to accomplish their tasks faster and handle an increased number of videos. Caarvida combines automatic video analysis with interactive and visual user interfaces. We conducted two case studies which show that Caarvida successfully supports domain experts and speeds up their task completion time.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
articleno = {6},
numpages = {9},
keywords = {visual analytics, object detection, automotive, information visualization, human computer interaction},
location = {Salerno, Italy},
series = {AVI '20}
}</textarea></div>
      
    </div>
  </div>
  
  
  <div class="paper small" id="papercutura2020comparing">
    
      <img
        id="imagecutura2020comparing"
        title="Click to enlarge and show details"
        onclick="toggleClass('papercutura2020comparing', 'small'); toggleImageSize(this)"
        class="publicationImage small"
        src="../img/small/cutura2020comparing.png"
      />
    <div class="metaData ">
      <h3
        onclick="toggleClass('papercutura2020comparing', 'small'); toggleImageSize(imagecutura2020comparing)"
        title="Click to show details"
      >
        Comparing and Exploring High-Dimensional Data with Dimensionality Reduction Algorithms and Matrix Visualizations<a class="anchor" name="cutura2020comparing"></a>
      </h3>
      <div>
        Rene Cutura, Michaël Aupetit, Jean-Daniel Fekete, Michael Sedlmair
      </div>
      <div>
        AVI  (2020) Full Paper
        <a href="https://doi.org/10.1145/3399715.3399875" target="_blank">website</a>
        <a href="../pdf/cutura2020comparing.pdf" target="_blank">PDF</a>
        <a href="https://youtu.be/UPkH7rc0ulU" target="_blank">video</a>
        
      </div>
    </div>
    <div class="info">
      <h4>Abstract</h4><div class="abstract">We propose Compadre, a tool for visual analysis for comparing distances of high-dimensional (HD) data and their low-dimensional projections. At the heart is a matrix visualization to represent the discrepancy between distance matrices, linked side-by-side with 2D scatterplot projections of the data. Using different examples and datasets, we illustrate how this approach fosters (1) evaluating dimensionality reduction techniques w.r.t. how well they project the HD data, (2) comparing them to each other side-by-side, and (3) evaluate important data features through subspace comparison. We also present a case study, in which we analyze IEEE VIS authors from 1990 to 2018, and gain new insights on the relationships between coauthors, citations, and keywords. The coauthors are projected as accurately with UMAP as with t-SNE but the projections show different insights. The structure of the citation subspace is very different from the coauthor subspace. The keyword subspace is noisy yet consistent among the three IEEE VIS sub-conferences.</div>
      <h4>BibTex</h4><div class="bibtex"><textarea>@inproceedings{cutura2020comparing,
  title={Comparing and exploring high-dimensional data with dimensionality reduction algorithms and matrix visualizations},
  author={Cutura, Rene and Aupetit, Micha{\"e}l and Fekete, Jean-Daniel and Sedlmair, Michael},
  booktitle={Proc. Intl. Conf. on Advanced Visual Interfaces (AVI)},
  pages={1--9},
  year={2020},
  doi={10.1145/3399715.3399875}}</textarea></div>
      <h4>Acknowledgements</h4><div class="abstract">This work was supported by the BMVIT ICT of the Future program via the ViSciPub project (no. 867378) and handled by the FFG.</div>
    </div>
  </div>
  
  
  <h2>2018</h2>
  
  <div class="paper small" id="papercutura2018viscoder">
    
      <img
        id="imagecutura2018viscoder"
        title="Click to enlarge and show details"
        onclick="toggleClass('papercutura2018viscoder', 'small'); toggleImageSize(this)"
        class="publicationImage small"
        src="../img/small/cutura2018viscoder.png"
      />
    <div class="metaData ">
      <h3
        onclick="toggleClass('papercutura2018viscoder', 'small'); toggleImageSize(imagecutura2018viscoder)"
        title="Click to show details"
      >
        VisCoDeR: A Tool for Visually Comparing Dimensionality Reduction Algorithms<a class="anchor" name="cutura2018viscoder"></a>
      </h3>
      <div>
        Rene Cutura, Stefan Holzer, Michaël Aupetit, Michael Sedlmair
      </div>
      <div>
        ESANN (2018) Full Paper
        
        <a href="../pdf/cutura2018viscoder.pdf" target="_blank">PDF</a>
        <a href="../video/cutura2018viscoder.mp4" target="_blank">video</a>
        
      </div>
    </div>
    <div class="info">
      <h4>Abstract</h4><div class="abstract">We propose VisCoDeR, a tool that leverages comparative visualization to support learning and analyzing different dimensionality reduction (DR) methods. VisCoDeR fosters two modes. The Discover mode allows qualitatively comparing several DR results by juxtaposing and linking the resulting scatterplots. The Explore mode allows for analyzing hundreds of differently parameterized DR results in a quantitative way. We present use cases that show that our approach helps to understand similarities and differences between DR algorithms.</div>
      <h4>BibTex</h4><div class="bibtex"><textarea>@inproceedings{cutura2018viscoder,
  title={{VisCoDeR: A Tool for Visually Comparing Dimensionality Reduction Algorithms}},
  author={Cutura, Rene and Holzer, Stefan and Aupetit, Micha{\"e}l and Sedlmair, Michael},
  booktitle={Euro. Symp. on Artificial Neural Networks, Computational Intelligence and Machine Learning (ESANN)},
  pages={641--646}
  year={2018}
}</textarea></div>
      
    </div>
  </div>
  
      </article>
    </div>
  </main>
</body>
</html>