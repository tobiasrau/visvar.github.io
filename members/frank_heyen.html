<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Frank Heyen | VISVAR Research Group, University of Stuttgart</title>
  <link rel="stylesheet" href="../style.css">
  <script src="../script.js"></script>
  <link rel="shortcut icon" href="../img/favicon.png">
  <link rel="icon" type="image/png" href="../img/favicon.png" sizes="256x256">
  <link rel="apple-touch-icon" sizes="256x256" href="../img/favicon.png">
</head>
<body>
  <a class="anchor" name="top"></a>
  <main>
    <div>
      
<header>
  <div>
    <a href="https://visvar.github.io/">
      <h1 class="h1desktop"><div>VISVAR</div><div>Research</div><div>Group</div></h1>
      <h1 class="h1mobile">VISVAR</h1>
    </a>
  </div>
  <div>
    <nav>
      <ul>
        <li>
          <a href="https://visvar.github.io/#aboutus">about VISVAR</a>
        </li>
        <li>
          <a href="https://visvar.github.io/#publications">publications</a>
        </li>
        <li class="memberNav">
          <a href="https://visvar.github.io/#members">members</a>
        </li>
        <ul class="memberNav">
          
            <li><a href="https://visvar.github.io/members/aimee_sousa_calepso.html">Aimee Sousa Calepso</a></li>
          
            <li><a href="https://visvar.github.io/members/alexander_achberger.html">Alexander Achberger</a></li>
          
            <li><a href="https://visvar.github.io/members/frank_heyen.html">Frank Heyen</a></li>
          
            <li><a href="https://visvar.github.io/members/jonas_haischt.html">Jonas Haischt</a></li>
          
            <li><a href="https://visvar.github.io/members/katrin_angerbauer.html">Katrin Angerbauer</a></li>
          
            <li><a href="https://visvar.github.io/members/melissa_reinelt.html">Melissa Reinelt</a></li>
          
            <li><a href="https://visvar.github.io/members/michael_sedlmair.html">Michael Sedlmair</a></li>
          
            <li><a href="https://visvar.github.io/members/natalie_hube.html">Natalie Hube</a></li>
          
            <li><a href="https://visvar.github.io/members/quynh_ngo.html">Quynh Ngo</a></li>
          
            <li><a href="https://visvar.github.io/members/rene_cutura.html">Rene Cutura</a></li>
          
            <li><a href="https://visvar.github.io/members/ruben_bauer.html">Ruben Bauer</a></li>
          
            <li><a href="https://visvar.github.io/members/sebastian_rigling.html">Sebastian Rigling</a></li>
          
            <li><a href="https://visvar.github.io/members/simeon_rau.html">Simeon Rau</a></li>
          
            <li><a href="https://visvar.github.io/members/xingyao_yu.html">Xingyao Yu</a></li>
          
        </ul>
      </ul>
    </nav>
  </div>
</header>
    </div>
    <div>
      <article> <a class="anchor" name="aboutus"></a>
        <h1>
  Frank Heyen, M.Sc.
</h1>

<div class="aboutMember">

  <div class="avatarAndBio">
    <img class="avatar" src="../img/people/frank_heyen.jpg" />

    <div class="bio">
      <p>
        My research focuses on data-driven music visualization, mainly to support music students and teachers.
        For eample, see
        <a href="https://vis2020-ieee.ipostersessions.com/default.aspx?s=82-F0-FF-F9-29-B9-B4-7F-FE-F3-A9-1D-4A-B7-4F-32"
          target="_blank">this poster</a>
        (<a href="../pdf/heyen2020supporting.pdf" target="_blank">PDF</a>) and
        <a href="../pdf/heyen2022datadriven.pdf" target="_blank">paper</a>
        (<a href="https://doi.org/10.48550/arxiv.2203.13320" target="_blank">DOI</a>,
        <a href="../video/heyen2022datadriven.mp4" target="_blank">video</a>)
        for how collecting and visualizing training data can
        help musicians learn their instruments more efficiently.
        <a href="../pdf/rau2021visual.pdf" target="_blank">Another poster</a>
        demonstrates visualization-supported collaboration between
        user and AI for composition.
      </p>
      <p>
        Future work: Leverage
        <a href="../pdf/heyen2022cellovis.pdf" target="_blank">VR/AR, motion capturing</a>,
        and ML/AI to achieve better and more situated visual
        support for musicians.
      </p>
    </div>
  </div>

  <p>
    <a href="https://www.visus.uni-stuttgart.de/en/institute/team/Heyen/" target="_blank">Institute website</a>
  </p>

  <h2>Research Interests</h2>
  <ul>
    <li>Visualization &amp; visual analytics</li>
    <li>Visual musicology</li>
    <li>VR/AR</li>
    <li>HCI</li>
  </ul>

  <h2>Projects &amp; Funding</h2>
  <a href="https://www.visus.uni-stuttgart.de/en/projects/cvrf-instrudata/" target="_blank">CyberValley - InstruData</a>

  <h2>More</h2>
  <ul>
    <li>
      <a href="https://fheyen.github.io/" target="_blank">Personal website</a>
    </li>
    <li>
      <a href="https://observablehq.com/@fheyen?tab=notebooks" target="_blank">Observable notebooks</a>
    </li>
    <li>
      <a href="https://orcid.org/0000-0002-5090-0133" target="_blank">ORCID</a>
    </li>
    <li>
      <a href="https://dblp.uni-trier.de/pid/276/2843.html" target="_blank">DBLP</a>
    </li>
    <li>
      <a href="https://arxiv.org/a/heyen_f_1.html" target="_blank">arXiv</a>
    </li>
  </ul>

</div>

      </article>
      <article> <a class="anchor" name="publications"></a>
        <h1>Publications</h1>
        
  <h2>2022</h2>
  <div class="paper small" id="paperachberger2022touching">
    
      <img
        id="imageachberger2022touching"
        title="Click to enlarge and show details"
        onclick="toggleClass('paperachberger2022touching', 'small'); toggleImageSize(this)"
        class="publicationImage small"
        src="../img/small/achberger2022touching.png"
      />
    <div class="metaData ">
      <h3
        onclick="toggleClass('paperachberger2022touching', 'small'); toggleImageSize(imageachberger2022touching)"
        title="Click to show details"
      >
        Touching Data with PropellerHand<a class="anchor" name="achberger2022touching"></a>
      </h3>
      <div>
        Alexander Achberger, Frank Heyen, Kresimir Vidackovic, Michael Sedlmair 
      </div>
      <div>
        J Vis (2022) Full Paper
        <a href="https://doi.org/10.1007/s12650-022-00859-2" target="_blank">website</a>
        <a href="../pdf/achberger2022touching.pdf" target="_blank">PDF</a>
        
        
      </div>
    </div>
    <div class="info">
      <h4>Abstract</h4><div class="abstract">Immersive analytics often takes place in virtual environments which promise the users immersion. To fulfill this promise, sensory feedback, such as haptics, is an important component, which is however not well supported yet. Existing haptic devices are often expensive, stationary, or occupy the user’s hand, preventing them from grasping objects or using a controller. We propose PropellerHand, an ungrounded hand-mounted haptic device with two rotatable propellers, that allows exerting forces on the hand without obstructing hand use. PropellerHand is able to simulate feedback such as weight and torque by generating thrust up to 11 N in 2-DOF and a torque of 1.87 Nm in 2-DOF. Its design builds on our experience from quantitative and qualitative experiments with different form factors and parts. We evaluated our prototype through a qualitative user study in various VR scenarios that required participants to manipulate virtual objects in different ways, while changing between torques and directional forces. Results show that PropellerHand improves users’ immersion in virtual reality. Additionally, we conducted a second user study in the field of immersive visualization to investigate the potential benefits of PropellerHand there.</div>
      <h4>BibTex</h4><div class="bibtex"><textarea>@article{achberger2022touching,
    title={Touching data with PropellerHand},
    author={Achberger, Alexander and Heyen, Frank and Vidackovic, Kresimir and Sedlmair, Michael},
    journal={Journal of Visualization},
    year={2022},
    doi={10.1007/s12650-022-00859-2},
    url={https://doi.org/10.1007/s12650-022-00859-2}
}</textarea></div>
      <h4>Acknowledgements</h4><div class="abstract">Partially supported by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under Germanys Excellence Strategy – EXC 2120/1 – 390831618</div>
      <div>
        <a href="https://visvar.github.io/pub/achberger2022touching.html" target="_blank">direct link</a>
      </div>
    </div>
  </div>
  
  
  <div class="paper small" id="paperheyen2022cellovis">
    
      <img
        id="imageheyen2022cellovis"
        title="Click to enlarge and show details"
        onclick="toggleClass('paperheyen2022cellovis', 'small'); toggleImageSize(this)"
        class="publicationImage small"
        src="../img/small/heyen2022cellovis.png"
      />
    <div class="metaData ">
      <h3
        onclick="toggleClass('paperheyen2022cellovis', 'small'); toggleImageSize(imageheyen2022cellovis)"
        title="Click to show details"
      >
        Immersive Visual Analysis of Cello Bow Movements<a class="anchor" name="heyen2022cellovis"></a>
      </h3>
      <div>
        Frank Heyen, Yannik Kohler, Sebastian Triebener, Sebastian Rigling, Michael Sedlmair
      </div>
      <div>
        CHI (2022) Workshop Paper
        <a href="https://doi.org/10.48550/arxiv.2203.13316" target="_blank">website</a>
        <a href="../pdf/heyen2022cellovis.pdf" target="_blank">PDF</a>
        <a href="../video/heyen2022cellovis.mp4" target="_blank">video</a>
        
      </div>
    </div>
    <div class="info">
      <h4>Abstract</h4><div class="abstract">We propose a 3D immersive visualization environment for analyzing the right hand movements of a cello player. To achieve this, we track the position and orientation of the cello bow and record audio. As movements mostly occur in a shallow volume and the motion is therefore mostly two-dimensional, we use the third dimension to encode time. Our concept further explores various mappings from motion and audio data to spatial and other visual attributes. We work in close cooperation with a cellist and plan to evaluate our prototype through a user study with a group of cellists in the near future.</div>
      <h4>BibTex</h4><div class="bibtex"><textarea>@misc{https://doi.org/10.48550/arxiv.2203.13316,
  doi = {10.48550/ARXIV.2203.13316},
  url = {https://arxiv.org/abs/2203.13316},
  author = {Heyen, Frank and Kohler, Yannik and Triebener, Sebastian and Rigling, Sebastian and Sedlmair, Michael},
  keywords = {Human-Computer Interaction (cs.HC), Graphics (cs.GR), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Immersive Visual Analysis of Cello Bow Movements},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}</textarea></div>
      <h4>Acknowledgements</h4><div class="abstract">Funded by Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under Germany’s Excellence Strategy - EXC 2075 - 390740016, and by Cyber Valley (InstruData project).</div>
      <div>
        <a href="https://visvar.github.io/pub/heyen2022cellovis.html" target="_blank">direct link</a>
      </div>
    </div>
  </div>
  
  
  <div class="paper small" id="paperheyen2022datadriven">
    
      <img
        id="imageheyen2022datadriven"
        title="Click to enlarge and show details"
        onclick="toggleClass('paperheyen2022datadriven', 'small'); toggleImageSize(this)"
        class="publicationImage small"
        src="../img/small/heyen2022datadriven.png"
      />
    <div class="metaData ">
      <h3
        onclick="toggleClass('paperheyen2022datadriven', 'small'); toggleImageSize(imageheyen2022datadriven)"
        title="Click to show details"
      >
        Data-Driven Visual Reflection on Music Instrument Practice<a class="anchor" name="heyen2022datadriven"></a>
      </h3>
      <div>
        Frank Heyen, Quynh Ngo, Kuno Kurzhals, Michael Sedlmair
      </div>
      <div>
        CHI (2022) Workshop Paper
        <a href="https://doi.org/10.48550/arxiv.2203.13320" target="_blank">website</a>
        <a href="../pdf/heyen2022datadriven.pdf" target="_blank">PDF</a>
        <a href="../video/heyen2022datadriven.mp4" target="_blank">video</a>
        
      </div>
    </div>
    <div class="info">
      <h4>Abstract</h4><div class="abstract">We propose a data-driven approach to music instrument practice that allows studying patterns and long-term trends through visualization. Inspired by life logging and fitness tracking, we imagine musicians to record their practice sessions over the span of months or years. The resulting data in the form of MIDI or audio recordings can then be analyzed sporadically to track progress and guide decisions. Toward this vision, we started exploring various visualization designs together with a group of nine guitarists, who provided us with data and feedback over the course of three months.</div>
      <h4>BibTex</h4><div class="bibtex"><textarea>@misc{https://doi.org/10.48550/arxiv.2203.13320,
  doi = {10.48550/ARXIV.2203.13320},
  url = {https://arxiv.org/abs/2203.13320},
  author = {Heyen, Frank and Ngo, Quynh Quang and Kurzhals, Kuno and Sedlmair, Michael},
  keywords = {Human-Computer Interaction (cs.HC), Graphics (cs.GR), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Data-Driven Visual Reflection on Music Instrument Practice},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution Share Alike 4.0 International}
}</textarea></div>
      <h4>Acknowledgements</h4><div class="abstract">Funded by Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under Germany’s Excellence Strategy - EXC 2075 - 390740016, and by Cyber Valley (InstruData project).</div>
      <div>
        <a href="https://visvar.github.io/pub/heyen2022datadriven.html" target="_blank">direct link</a>
      </div>
    </div>
  </div>
  
  
  <div class="paper small" id="paperskreinig2022ar">
    
      <img
        id="imageskreinig2022ar"
        title="Click to enlarge and show details"
        onclick="toggleClass('paperskreinig2022ar', 'small'); toggleImageSize(this)"
        class="publicationImage small"
        src="../img/small/skreinig2022ar.png"
      />
    <div class="metaData ">
      <h3
        onclick="toggleClass('paperskreinig2022ar', 'small'); toggleImageSize(imageskreinig2022ar)"
        title="Click to show details"
      >
        AR Hero: Generating Interactive Augmented Reality Guitar Tutorials<a class="anchor" name="skreinig2022ar"></a>
      </h3>
      <div>
        Lucchas Ribeiro Skreinig, Ana Stanescu, Shohei Mori, Frank Heyen, Peter Mohr, Michael Sedlmair, Dieter Schmalstieg, Denis Kalkofen
      </div>
      <div>
        VRW (2022) 
        <a href="https://doi.org/10.1109/VRW55335.2022.00086" target="_blank">website</a>
        <a href="../pdf/skreinig2022ar.pdf" target="_blank">PDF</a>
        
        
      </div>
    </div>
    <div class="info">
      <h4>Abstract</h4><div class="abstract">We introduce a system capable of generating interactive Augmented Reality guitar tutorials by parsing common digital guitar tablature and by capturing the performance of an expert using a multi-camera array. Instructions are presented to the user in an Augmented Reality application using either an abstract visualization, a 3D virtual hand, or a 3D video. To support individual users at different skill levels the system provides full control of the playback of a tutorial, including its speed and looping behavior, while delivering live feedback on the user’s performance.</div>
      <h4>BibTex</h4><div class="bibtex"><textarea>@INPROCEEDINGS{9757565,
  author={Skreinig, Lucchas Ribeiro and Stanescu, Ana and Mori, Shohei and Heyen, Frank and Mohr, Peter and Sedlmair, Michael and Schmalstieg, Dieter and Kalkofen, Denis},
  booktitle={2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)}, 
  title={AR Hero: Generating Interactive Augmented Reality Guitar Tutorials}, 
  year={2022},
  pages={395-401},
  doi={10.1109/VRW55335.2022.00086}}</textarea></div>
      
      <div>
        <a href="https://visvar.github.io/pub/skreinig2022ar.html" target="_blank">direct link</a>
      </div>
    </div>
  </div>
  
  <h2>2021</h2>
  <div class="paper small" id="paperrau2021visual">
    
      <img
        id="imagerau2021visual"
        title="Click to enlarge and show details"
        onclick="toggleClass('paperrau2021visual', 'small'); toggleImageSize(this)"
        class="publicationImage small"
        src="../img/small/rau2021visual.png"
      />
    <div class="metaData ">
      <h3
        onclick="toggleClass('paperrau2021visual', 'small'); toggleImageSize(imagerau2021visual)"
        title="Click to show details"
      >
        Visual Support for Human-AI Co-Composition<a class="anchor" name="rau2021visual"></a>
      </h3>
      <div>
        Simeon Rau, Frank Heyen, Michael Sedlmair
      </div>
      <div>
        ISMIR (2021) Late-Breaking Demo Poster
        <a href="https://archives.ismir.net/ismir2021/latebreaking/000014.pdf" target="_blank">website</a>
        <a href="../pdf/rau2021visual.pdf" target="_blank">PDF</a>
        <a href="../video/rau2021visual.mp4" target="_blank">video</a>
        
      </div>
    </div>
    <div class="info">
      <h4>Abstract</h4><div class="abstract">We propose a visual approach for AI-assisted music composition, where the user interactively generates, selects, and adapts short melodies. Based on an entered start melody, we automatically generate multiple continuation samples. Repeating this step and in turn generating continuations for these samples results in a tree or graph of melodies. We visualize this structure with two visualizations, where nodes display the piano roll of the corresponding sample. By interacting with these visualizations, the user can quickly listen to, choose, and adapt melodies, to iteratively create a composition. A third visualization provides an overview over larger numbers of samples, allowing for insights into the AI's predictions and the sample space.</div>
      <h4>BibTex</h4><div class="bibtex"><textarea>@inproceedings{rau2021visual,
  title={Visual Support for Human-{AI} Co-Composition},
  author={Rau, Simeon and Heyen, Frank and Sedlmair, Michael},
  year={2021},
  booktitle={Extended Abstracts for the Late-Breaking Demo Session of the 22nd Int. Society for Music Information Retrieval Conf. (ISMIR)},
  url={https://archives.ismir.net/ismir2021/latebreaking/000014.pdf}
}</textarea></div>
      <h4>Acknowledgements</h4><div class="abstract">This work was funded by the Cyber Valley Research Fund – Project InstruData.</div>
      <div>
        <a href="https://visvar.github.io/pub/rau2021visual.html" target="_blank">direct link</a>
      </div>
    </div>
  </div>
  
  
  <div class="paper small" id="papercutura2021visap">
    
      <img
        id="imagecutura2021visap"
        title="Click to enlarge and show details"
        onclick="toggleClass('papercutura2021visap', 'small'); toggleImageSize(this)"
        class="publicationImage small"
        src="../img/small/cutura2021visap.png"
      />
    <div class="metaData ">
      <h3
        onclick="toggleClass('papercutura2021visap', 'small'); toggleImageSize(imagecutura2021visap)"
        title="Click to show details"
      >
        DaRt: Generative Art using Dimensionality Reduction Algorithms<a class="anchor" name="cutura2021visap"></a>
      </h3>
      <div>
        Rene Cutura, Katrin Angerbauer, Frank Heyen, Natalie Hube, Michael Sedlmair
      </div>
      <div>
        VIS (2021) Pictorial
        <a href="https://doi.org/10.1109/VISAP52981.2021.00013" target="_blank">website</a>
        <a href="../pdf/cutura2021visap.pdf" target="_blank">PDF</a>
        <a href="https://youtu.be/pOcksJOiAPw" target="_blank">video</a>
        
      </div>
    </div>
    <div class="info">
      <h4>Abstract</h4><div class="abstract">Dimensionality Reduction (DR) is a popular technique that is often used in Machine Learning and Visualization communities to analyze high-dimensional data. The approach is empirically proven to be powerful for uncovering previously unseen structures in the data. While observing the results of the intermediate optimization steps of DR algorithms, we coincidently discovered the artistic beauty of the DR process. With enthusiasm for the beauty, we decided to look at DR from a generative art lens rather than their technical application aspects and use DR techniques to create artwork. Particularly, we use the optimization process to generate images, by drawing each intermediate step of the optimization process with some opacity over the previous intermediate result. As another alternative input, we used a neural-network model for face-landmark detection, to apply DR to portraits, while maintaining some facial properties, resulting in abstracted facial avatars. In this work, we provide such a collection of such artwork.</div>
      <h4>BibTex</h4><div class="bibtex"><textarea>@inproceedings{cutura2021dart,
  title={{DaRt}: Generative Art using Dimensionality Reduction Algorithms},
  author={Cutura, Rene and Angerbauer, Katrin and Heyen, Frank and Hube, Natalie and Sedlmair, Michael},
  booktitle={2021 IEEE VIS Arts Program (VISAP)},
  pages={59--72},
  year={2021},
  organization={IEEE},
}</textarea></div>
      <h4>Acknowledgements</h4><div class="abstract">Funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) - Project-ID 251654672 - TRR 161</div>
      <div>
        <a href="https://visvar.github.io/pub/cutura2021visap.html" target="_blank">direct link</a>
      </div>
    </div>
  </div>
  
  
  <div class="paper small" id="paperachberger2021vinci">
    
      <img
        id="imageachberger2021vinci"
        title="Click to enlarge and show details"
        onclick="toggleClass('paperachberger2021vinci', 'small'); toggleImageSize(this)"
        class="publicationImage small"
        src="../img/small/achberger2021vinci.png"
      />
    <div class="metaData ">
      <h3
        onclick="toggleClass('paperachberger2021vinci', 'small'); toggleImageSize(imageachberger2021vinci)"
        title="Click to show details"
      >
        PropellerHand: Hand-Mounted, Propeller-Based Force Feedback Device<a class="anchor" name="achberger2021vinci"></a>
      </h3>
      <div>
        Alexander Achberger, Frank Heyen, Kresimir Vidackovic, Michael Sedlmair
      </div>
      <div>
        VINCI (2021) Full Paper
        <a href="https://doi.org/10.1145/3481549.3481563" target="_blank">website</a>
        <a href="../pdf/achberger2021vinci.pdf" target="_blank">PDF</a>
        
        
      </div>
    </div>
    <div class="info">
      <h4>Abstract</h4><div class="abstract">Immersive analytics is a fast growing field that is often applied in virtual reality (VR). VR environments often lack immersion due to missing sensory feedback when interacting with data. Existing haptic devices are often expensive, stationary, or occupy the user’s hand, preventing them from grasping objects or using a controller. We propose PropellerHand, an ungrounded hand-mounted haptic device with two rotatable propellers, that allows exerting forces on the hand without obstructing hand use. PropellerHand is able to simulate feedback such as weight and torque by generating thrust up to 11 N in 2-DOF and a torque of 1.87 Nm in 2-DOF. Its design builds on our experience from quantitative and qualitative experiments with different form factors and parts. We evaluated our final version through a qualitative user study in various VR scenarios that required participants to manipulate virtual objects in different ways, while changing between torques and directional forces. Results show that PropellerHand improves users’ immersion in virtual reality.</div>
      <h4>BibTex</h4><div class="bibtex"><textarea>@inproceedings{achberger2021vinci,
  author = {Alexander Achberger and Frank Heyen and Kresimir Vidackovic and Michael Sedlmair},
  title = {PropellerHand: {A} Hand-Mounted, Propeller-Based Force Feedback Device},
  booktitle = {International Symposium on Visual Information Communication and Interaction (VINCI)},
  pages     = {4:1--4:8},
  publisher = {ACM},
  year      = {2021},
  url       = {https://doi.org/10.1145/3481549.3481563},
  doi       = {10.1145/3481549.3481563}
}</textarea></div>
      
      <div>
        <a href="https://visvar.github.io/pub/achberger2021vinci.html" target="_blank">direct link</a>
      </div>
    </div>
  </div>
  
  
  <div class="paper small" id="paperrijken2021illegible">
    
      <img
        id="imagerijken2021illegible"
        title="Click to enlarge and show details"
        onclick="toggleClass('paperrijken2021illegible', 'small'); toggleImageSize(this)"
        class="publicationImage small"
        src="../img/small/rijken2021illegible.png"
      />
    <div class="metaData ">
      <h3
        onclick="toggleClass('paperrijken2021illegible', 'small'); toggleImageSize(imagerijken2021illegible)"
        title="Click to show details"
      >
        Illegible Semantics: Exploring the Design Space of Metal Logos<a class="anchor" name="rijken2021illegible"></a>
      </h3>
      <div>
        Gerrit J. Rijken, Rene Cutura, Frank Heyen, Michael Sedlmair, Michael Correll, Jason Dykes, Noeska Smit
      </div>
      <div>
        alt.VIS (2021) Workshop Paper
        <a href="https://doi.org/10.48550/arXiv.2109.01688" target="_blank">website</a>
        <a href="https://arxiv.org/ftp/arxiv/papers/2109/2109.01688.pdf" target="_blank">PDF</a>
        <a href="https://www.youtube.com/watch?v=BZOdIhU-mrA" target="_blank">video</a>
        <a href="http://illegiblesemantics.com" target="_blank">supplemental</a>
      </div>
    </div>
    <div class="info">
      <h4>Abstract</h4><div class="abstract">The logos of metal bands can be by turns gaudy, uncouth, or nearly illegible. Yet, these logos work: they communicate sophisticated notions of genre and emotional affect. In this paper we use the design considerations of metal logos to explore the space of “illegible semantics”: the ways that text can communicate information at the cost of readability, which is not always the most important objective. In this work, drawing on formative visualization theory, professional design expertise, and empirical assessments of a corpus ofmetal band logos, we describe a design space of metal logos and present a tool through which logo characteristics can be explored through visualization. We investigate ways in which logo designers imbue their text with meaning and consider opportunities and implications for visualization more widely.</div>
      <h4>BibTex</h4><div class="bibtex"><textarea>@inproceedings{rijken2021altvis,
	Author = {Gerrit J Rijken and Rene Cutura and Frank Heyen and Michael Sedlmair and Michael Correll and Jason Dykes and Noeska Smit},
	Title = {Illegible Semantics: Exploring the Design Space of Metal Logos},
	Booktitle = {{IEEE VIS} alt.VIS Workshop},
	url = {https://arxiv.org/abs/2109.01688},
	Year = {2021}
}</textarea></div>
      
      <div>
        <a href="https://visvar.github.io/pub/rijken2021illegible.html" target="_blank">direct link</a>
      </div>
    </div>
  </div>
  
  <h2>2020</h2>
  <div class="paper small" id="paperheyen2020supporting">
    
      <img
        id="imageheyen2020supporting"
        title="Click to enlarge and show details"
        onclick="toggleClass('paperheyen2020supporting', 'small'); toggleImageSize(this)"
        class="publicationImage small"
        src="../img/small/heyen2020supporting.png"
      />
    <div class="metaData ">
      <h3
        onclick="toggleClass('paperheyen2020supporting', 'small'); toggleImageSize(imageheyen2020supporting)"
        title="Click to show details"
      >
        Supporting Music Education through Visualizations of MIDI Recordings<a class="anchor" name="heyen2020supporting"></a>
      </h3>
      <div>
        Frank Heyen, Michael Sedlmair
      </div>
      <div>
        VIS (2020) Poster
        <a href="https://vis2020-ieee.ipostersessions.com/default.aspx?s=82-F0-FF-F9-29-B9-B4-7F-FE-F3-A9-1D-4A-B7-4F-32" target="_blank">website</a>
        <a href="../pdf/heyen2020supporting.pdf" target="_blank">PDF</a>
        
        
      </div>
    </div>
    <div class="info">
      <h4>Abstract</h4><div class="abstract">Musicians mostly have to rely on their ears when they want to analyze what they play, for example to detect errors. Since hearing is sequential, it is not possible to quickly grasp an overview over one or multiple recordings of a whole piece of music at once. We therefore propose various visualizations that allow analyzing errors and stylistic variance. Our current approach focuses on rhythm and uses MIDI data for simplicity.</div>
      
      
      <div>
        <a href="https://visvar.github.io/pub/heyen2020supporting.html" target="_blank">direct link</a>
      </div>
    </div>
  </div>
  
  
  <div class="paper small" id="paperheyen2020clavis">
    
      <img
        id="imageheyen2020clavis"
        title="Click to enlarge and show details"
        onclick="toggleClass('paperheyen2020clavis', 'small'); toggleImageSize(this)"
        class="publicationImage small"
        src="../img/small/heyen2020clavis.png"
      />
    <div class="metaData ">
      <h3
        onclick="toggleClass('paperheyen2020clavis', 'small'); toggleImageSize(imageheyen2020clavis)"
        title="Click to show details"
      >
        ClaVis: An Interactive Visual Comparison System for Classifiers<a class="anchor" name="heyen2020clavis"></a>
      </h3>
      <div>
        Frank Heyen, Tanja Munz, Michael Neumann, Daniel Ortega, Ngoc Thang Vu, Daniel Weiskopf, Michael Sedlmair
      </div>
      <div>
        AVI (2020) Full Paper
        <a href="https://doi.org/10.1145/3399715.3399814" target="_blank">website</a>
        <a href="../pdf/heyen2020clavis.pdf" target="_blank">PDF</a>
        
        <a href="https://github.com/fheyen/clavis" target="_blank">supplemental</a>
      </div>
    </div>
    <div class="info">
      <h4>Abstract</h4><div class="abstract">We propose ClaVis, a visual analytics system for comparative analysis of classification models. ClaVis allows users to visually compare the performance and behavior of tens to hundreds of classifiers trained with different hyperparameter configurations. Our approach is plugin-based and classifier-agnostic and allows users to add their own datasets and classifier implementations. It provides multiple visualizations, including a multivariate ranking, a similarity map, a scatterplot that reveals correlations between parameters and scores, and a training history chart. We demonstrate the effectivity of our approach in multiple case studies for training classification models in the domain of natural language processing.</div>
      <h4>BibTex</h4><div class="bibtex"><textarea>@inproceedings{10.1145/3399715.3399814,
author = {Heyen, Frank and Munz, Tanja and Neumann, Michael and Ortega, Daniel and Vu, Ngoc Thang and Weiskopf, Daniel and Sedlmair, Michael},
title = {ClaVis: An Interactive Visual Comparison System for Classifiers},
year = {2020},
isbn = {9781450375351},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3399715.3399814},
doi = {10.1145/3399715.3399814},
abstract = {We propose ClaVis, a visual analytics system for comparative analysis of classification
models. ClaVis allows users to visually compare the performance and behavior of tens
to hundreds of classifiers trained with different hyperparameter configurations. Our
approach is plugin-based and classifier-agnostic and allows users to add their own
datasets and classifier implementations. It provides multiple visualizations, including
a multivariate ranking, a similarity map, a scatterplot that reveals correlations
between parameters and scores, and a training history chart. We demonstrate the effectivity
of our approach in multiple case studies for training classification models in the
domain of natural language processing.},
booktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},
articleno = {9},
numpages = {9},
keywords = {visual analytics, Visualization, machine learning, classifier comparison},
location = {Salerno, Italy},
series = {AVI '20}
}</textarea></div>
      <h4>Acknowledgements</h4><div class="abstract">Funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) – Project-ID 251654672 – TRR 161 (A08) and under Germany’s Excellence Strategy – EXC-2075 – 39074001</div>
      <div>
        <a href="https://visvar.github.io/pub/heyen2020clavis.html" target="_blank">direct link</a>
      </div>
    </div>
  </div>
  
      </article>
    </div>
  </main>
</body>
</html>